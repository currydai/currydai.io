<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://currydai.com</id>
    <title>Currydai</title>
    <updated>2021-04-27T16:12:47.916Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://currydai.com"/>
    <link rel="self" href="https://currydai.com/atom.xml"/>
    <subtitle>Share interesting things</subtitle>
    <logo>https://currydai.com/images/avatar.png</logo>
    <icon>https://currydai.com/favicon.ico</icon>
    <rights>All rights reserved 2021, Currydai</rights>
    <entry>
        <title type="html"><![CDATA[【机器学习】机器学习与深度学习高级训练营]]></title>
        <id>https://currydai.com/post/ji-qi-xue-xi-ji-qi-xue-xi-yu-shen-du-xue-xi-gao-ji-xun-lian-ying/</id>
        <link href="https://currydai.com/post/ji-qi-xue-xi-ji-qi-xue-xi-yu-shen-du-xue-xi-gao-ji-xun-lian-ying/">
        </link>
        <updated>2021-04-19T14:15:25.000Z</updated>
        <content type="html"><![CDATA[<p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>b</mi><mi>e</mi><mi>g</mi><mi>i</mi><mi>n</mi></mrow><annotation encoding="application/x-tex">begin
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathdefault">b</span><span class="mord mathdefault">e</span><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="mord mathdefault">i</span><span class="mord mathdefault">n</span></span></span></span></span></p>
<h2 id="1-python基础">1. Python基础</h2>
<h2 id="2-多元回归和逻辑回归">2. 多元回归和逻辑回归</h2>
<h2 id="3-决策树和随机森林">3. 决策树和随机森林</h2>
<h2 id="4svm">4.SVM</h2>
<h2 id="5聚类">5.聚类</h2>
<h2 id="6em算法">6.EM算法</h2>
<h2 id="7隐马尔科夫模型hmm">7.隐马尔科夫模型HMM</h2>
<h2 id="8主题模型ldv">8.主题模型LDV</h2>
<h2 id="9卷积神经网络cnn">9.卷积神经网络CNN</h2>
<h2 id="10图像视频的定位与识别">10.图像视频的定位与识别</h2>
<h2 id="11循环神经网络rnn">11.循环神经网络RNN</h2>
<h2 id="12nlp">12.NLP</h2>
<h2 id="13生成对抗网络gan">13.生成对抗网络GAN</h2>
<h2 id="14强化学习">14.强化学习</h2>
<p><strong>课程地址：https://www.bilibili.com/video/BV1Ei4y1u7No?p=1</strong></p>
<p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>e</mi><mi>n</mi><mi>d</mi></mrow><annotation encoding="application/x-tex">end
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathdefault">e</span><span class="mord mathdefault">n</span><span class="mord mathdefault">d</span></span></span></span></span></p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[【编程】数据结构与算法(极客大学)]]></title>
        <id>https://currydai.com/post/bian-cheng-shu-ju-jie-gou-yu-suan-fa-ji-chu-ban/</id>
        <link href="https://currydai.com/post/bian-cheng-shu-ju-jie-gou-yu-suan-fa-ji-chu-ban/">
        </link>
        <updated>2021-03-21T14:10:04.000Z</updated>
        <content type="html"><![CDATA[<h2 id="前期准备">前期准备</h2>
<h3 id="1-刷题技巧">1. 刷题技巧</h3>
<pre><code>1. 看会or不会
2. 学多种题解(国际版前三回答)
3. 当天理解会写
4. 隔一天独立重复-
5. 隔一周独立重复
</code></pre>
<h3 id="2-代码规范">2. 代码规范</h3>
<pre><code>1. 谷歌code style
    - C++/python：https://zh-google-styleguide.readthedocs.io/en/latest/contents/
2. 指法和小技巧(top tips)
3. 自顶向下的编程方式
    - https://www.markhneedham.com/blog/2008/09/15/clean-code-book-review/
4. vscode风格配置
    - https://juejin.cn/post/6844903846871842823
5. vscode与leetcode配置
    - leetcode插件安装：leetcode
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[【编程】C++开发遇到的一些问题和解释整理]]></title>
        <id>https://currydai.com/post/bian-cheng-ckai-fa-yu-dao-de-yi-xie-wen-ti-he-jie-shi-zheng-li/</id>
        <link href="https://currydai.com/post/bian-cheng-ckai-fa-yu-dao-de-yi-xie-wen-ti-he-jie-shi-zheng-li/">
        </link>
        <updated>2021-03-17T13:29:41.000Z</updated>
        <content type="html"><![CDATA[<h4 id="在实践中常常遇到一些方法或者名词发生混淆-本着好记性不如烂笔头那就全都整理一起">在实践中，常常遇到一些方法或者名词发生混淆。本着好记性不如烂笔头，那就全都整理一起。</h4>
<h2 id="0基础相关">0.基础相关</h2>
<h3 id="01-指针-引用-解引用">0.1 指针 引用 解引用</h3>
<p>在c++中，*和&amp;在不同的地方有着不同的意义。</p>
<ul>
<li>引用：&amp;表示的是引用，就表示函数内的变量和主函数的变量是同一个，函数内改变它的值，主函数相应的变量也就跟着改变了；没有&amp;符号，就表示函数内的变量是主函数的变量的一个副本，在函数内改变其值，是不会改变主函数中变量的值的。</li>
<li>解引用：直接去寻找指针所指的地址里面的内容，此内容可以是任何数据类型，当然也可以是指针。例如下面代码，此时的*表示声明一个指针p,第5行让指针p指向a的地址。因此第6行输出的是a在内存中的地址。而第7行就是解引用。具体解释指针p所指向的内存地址里存放的内容。</li>
</ul>
<pre><code> 1 #include &lt;iostream&gt;
 2 using namespace std;
 3 int main(){
 4     int *p ,a=6;
 5     p=&amp;a;
 6     cout&lt;&lt;p&lt;&lt;endl;
 7     cout&lt;&lt;*p&lt;&lt;endl;
 8 //    cout&lt;&lt;&amp;*p&lt;&lt;endl;
 9 //    cout&lt;&lt;*(&amp;*p)&lt;&lt;endl;
10     return 0;
11 }
</code></pre>
<h2 id="1类与对象相关">1.类与对象相关</h2>
<h3 id="11对象指针">1.1对象指针</h3>
<p>对象的声明有两种，一种在栈上，一种在堆上。因此类的成员函数有两种调用方式，一种是由对象调用，另一种是由对象指针调用。</p>
<pre><code>//=============================================
//对象指针使用成员函数
//=============================================

#include &lt;iostream&gt;
#include &lt;iomanip&gt;
using namespace std;

/**
*类定义体
*/
class Date{
private:
    int year,month,day;
public:
    //在类定义体内定义成员函数，不需要在函数名前冠以类名
    void set(int y,int m,int d)
    {
        year = y;
        month = m;
        day = d;
    };
    bool isLeapYear();
    void print();
};


//使用日期类
int main()
{
    Date* dp = new Date;
    dp-&gt;set(2018,2,6);
    if((*dp).isLeapYear())
    {
        dp-&gt;print();
    }
    return 0;
}

//成员函数类定义体外定义

inline bool Date::isLeapYear() //显示内联
{
    return (year%4==0 &amp;&amp; year%100!=0)||(year%400==0);
}

void Date::print()
{
    cout&lt;&lt;setfill('0');
    cout&lt;&lt;setw(4)&lt;&lt;year&lt;&lt;'-'&lt;&lt;setw(2)&lt;&lt;month&lt;&lt;'-'&lt;&lt;setw(2)&lt;&lt;day&lt;&lt;'\n';
    cout&lt;&lt;setfill(' ');
}
</code></pre>
<p>特别需要注意的是：</p>
<ol>
<li>无虚函数的继承</li>
</ol>
<ul>
<li>如果以一个基础类指针指向一个派生类对象，那么经由该指针只能访问基础类定义的函数（静态绑定）。</li>
<li>如果以一个派生类类指针指向一个基础类对象，必须先做强制转型动作（explicit cast），这种做法很危险，也不符合生活习惯，在程序设计上也会给程序员带来困扰。（一般不会这么去使用）<br>
通常来说，子类总是含有一些父类没有的成员变量，或者方法函数。而子类肯定含有父类所有的成员变量和方法函数。所以用父类指针指向子类时，没有问题，因为父类有的，子类都有，不会出现非法访问问题。</li>
</ul>
<ol start="2">
<li>有虚函数的继承</li>
</ol>
<ul>
<li>有虚函数的继承，那么父类指针指向子类对象就是我们常见的多态实现，也就是动态。</li>
<li>在父类里可以声明纯虚函数和定义虚函数，使用父类指针访问虚函数或纯虚函数的时候，访问到的是子类里重写的函数。当然，对于虚函数，如果子类里没有对其重写的话，仍然访问到父类里定义的虚函数。可见虚函数和纯虚函数的却别仅仅在于：纯虚函数没有定义,只有声明。</li>
</ul>
<ol start="3">
<li>代码演示</li>
</ol>
<pre><code>#include &lt;iostream&gt;
using namespace std;
 
class Base_J 
{
public:
	Base_J()
	{
		cout &lt;&lt; &quot;Base Created&quot; &lt;&lt; endl;
	}
	~Base_J()
    //virtual ~Base_J()
	{
		cout &lt;&lt; &quot;Base Destroyed&quot; &lt;&lt; endl;
	}
};
 
class Derived_J : public Base_J
{
public:
	Derived_J()
	{
		cout &lt;&lt; &quot;Derived Created&quot; &lt;&lt; endl;
	}
	~Derived_J()
	{
		cout &lt;&lt; &quot;Derived Destroyed&quot; &lt;&lt; endl;
	}
};
 
int main()
{
	Base_J *pB = new Derived_J();
	delete pB;
	pB = NULL;
	system(&quot;pause&quot;);
	return 0;
</code></pre>
<ul>
<li>如果父类析构函数没有virtual,依次会输出：Base Destroyed，Derived Created，Base Destroyed</li>
<li>如果父类析构函数中有virtual，依次会输出：Base Destroyed，Derived Created，Derived Destroyed，Base Destroyed<br>
因此静态绑定时，对象销毁时只调用了父类的析构函数。如果这时子类的析构函数中有关于内存释放的操作，将会造成内存泄露。所以需要给父类的析构函数加上virtual。<br>
切记：<strong>C++中开发中，基类中的析构函数一般都是虚函数</strong></li>
</ul>
<h3 id="12-静态类成员">1.2 静态类成员</h3>
<p>无论创建多少了对象，程序都只创建一个静态类变量副本，类的所有对象都共享同一个静态成员。这对于所有类对象都具有相同值的类私有数据是非常方便的。但是不能再类的声明中初始化静态成员变量，要在类外声明。</p>
<ul>
<li>使用场景：构造函数中包含static变量++以及析构函数中包含--就可以统计类的对象总数</li>
<li>类里面定义一个指向自己的静态成员指针变量</li>
</ul>
<pre><code>class a
{
 public:
        void  printa() { cout&lt;&lt;&quot;class a&quot;;}
 public:
       static a* my;
}
</code></pre>
<p>在类里面定义自己的一个静态变量，当这个类的所有对象都需要与某个同类的对象发生关系时，就这么用。这个静态成员一般是全局存在的（废话），而且有特殊地位的对象。注意，static成员一定要在类外初始化！！</p>
<h3 id="13-构造函数">1.3 构造函数</h3>
<p>该类对象被创建时，编译系统对象分配内存空间，并自动调用该构造函数-&gt;<strong>由构造函数完成成员的初始化工作</strong>。<br>
构造函数的种类：</p>
<ul>
<li>无参数构造函数：如果创建一个类你没有写任何构造函数,则系统会自动生成默认的无参构造函数，函数为空，什么都不做。</li>
<li>一般构造函数（也称重载构造函数）:一般构造函数可以有各种参数形式,一个类可以有多个一般构造函数，前提是参数的个数或者类型不同（基于c++的重载函数原理）<pre><code>class Point
  {
  public:
      int x;
      int y;
  public:
      Point()
      {
          this-&gt;x=0;
          this-&gt;y=0;
      }
      Point(int x,int y)
      {
          this-&gt;x=x;
          this-&gt;y=y;
      }
  };
</code></pre>
</li>
<li>复制构造函数（也称为拷贝构造函数）:新建一个对象并将其初始化为同类现有对象时，复制构造函数都将被调用。这在很多情况下都可能发生，最常见的情况是新对象显式地初始化为现有的对象。例如，假设motto是一个StringBad对象，则下面4种声明都将调用复制构造函数：</li>
</ul>
<pre><code>StringBad ditto(motto);
StringBad metoo = motto;
StringBad also = StringBad(motto);
StringBad * pStringBad = new StringBad(motto);
</code></pre>
<pre><code>class Node
{
public:
    int index;
    Node* left;
    Node* right;
public:
    Node(int i)   //构造函数，带一个参数
    {
        index=i;
        left=0;
        right=0;
    }
    Node()    //构造函数，不带参数
    {
        index=0;
        left=0;
        right=0;
    }
    Node（const Node&amp; t)  //拷贝构造函数的特点是参数表是一个(const className&amp;),t是自定义的变量名
    {
        this-&gt;index=t.index;
        left=0;
        right=0;
    }
}
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[【机器学习】基于Keras框架的GPU加速环境搭建]]></title>
        <id>https://currydai.com/post/ji-qi-xue-xi-ji-yu-keras-kuang-jia-de-gpu-jia-su-huan-jing-da-jian/</id>
        <link href="https://currydai.com/post/ji-qi-xue-xi-ji-yu-keras-kuang-jia-de-gpu-jia-su-huan-jing-da-jian/">
        </link>
        <updated>2021-03-16T07:25:28.000Z</updated>
        <content type="html"><![CDATA[<h2 id="1安装包准备">1.安装包准备</h2>
<ul>
<li>CUDA<br>
https://developer.nvidia.com/zh-cn/cuda-downloads?target_os=Windows&amp;target_arch=x86_64</li>
<li>CUDNN<br>
https://developer.nvidia.com/cudnn-download-survey</li>
<li>tensorflow<br>
pip install tensorflow</li>
<li>Geforce Experience<br>
一般有独显环境下自带，需要利用此工具升级显卡驱动</li>
</ul>
<h2 id="2安装过程">2.安装过程</h2>
<h3 id="21cuda安装">2.1CUDA安装</h3>
<p>正常流程安装，根据需求自己选择安装服务，不知道的直接一路确认安装。</p>
<h3 id="22cudnn安装">2.2CUDNN安装</h3>
<h2 id="3环境变量配置">3.环境变量配置</h2>
<p>##4. 安装测试</p>
<p>##5. 特殊问题解决</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[【编程】C++编程实例]]></title>
        <id>https://currydai.com/post/bian-cheng-cbian-cheng-shi-li/</id>
        <link href="https://currydai.com/post/bian-cheng-cbian-cheng-shi-li/">
        </link>
        <updated>2021-03-13T14:06:31.000Z</updated>
        <content type="html"><![CDATA[<p>C++内容实在是太多，学完一遍又一遍总是晕头转向。回想起学python的过程中，由于项目压力逼迫自己边学边做，后来成长的特别快。因此在本文中，我会结合一些工作和学习中遇到的实例来练习C++的使用。</p>
<h2 id="1读文件改文件以及保存不同文件">1.读文件，改文件以及保存不同文件</h2>
<h3 id="11-不同格式文件的读入和保存">1.1 不同格式文件的读入和保存</h3>
<h4 id="基础知识">基础知识</h4>
<p><strong>C++中的数据类型：</strong></p>
<ul>
<li>1字节：char</li>
<li>2字节：short</li>
<li>4字节：int float long</li>
<li>8字节：double longlong<br>
此外，4中整型都有一种不能储存负数值的无符号变体（unsigned），主要优点是增大变量的储存最大值。</li>
</ul>
<p><strong>重载的&lt;&lt; and &gt;&gt;运算符：</strong><br>
对于上述的每一个数据类型，sotream都提供了operator()函数的定义(重载)</p>
<p><strong>.txt格式文件读取</strong></p>
<pre><code>#include&lt;iostream&gt;
#include&lt;fstream&gt;
#include&lt;string&gt;
using namespace std;

int main(int argc,char *argv[])
{

	cout &lt;&lt; &quot;argc&quot; &lt;&lt; &quot;:&quot;&lt;&lt;argc &lt;&lt; endl;
	cout &lt;&lt; &quot;*argv&quot; &lt;&lt; &quot;:&quot; &lt;&lt; *argv &lt;&lt; endl;
    //文件写操作
	ofstream fout(&quot;test.txt&quot;);

	string a = &quot;abc&quot;;
	int b[2][2];
	for (int i = 0; i &lt; 2; i++)
	{
		for (int j = 0; j &lt; 2; j++)
		{
			b[i][j] = i + j;
			fout &lt;&lt; b[i][j];
			fout &lt;&lt; &quot; &quot;;
		}
		fout &lt;&lt; '\n';
	}
	fout.close();
	cout &lt;&lt; &quot;文件保存结束&quot; &lt;&lt; endl;


	//文件读操作
	ifstream fin(&quot;test.txt&quot;);
	//char c;
	//fin &gt;&gt; c;


	string d;
	while (getline(fin, d))
	{
		cout &lt;&lt; d &lt;&lt; endl;
	}

	cout &lt;&lt; &quot;文件读取结束&quot; &lt;&lt; endl;
	fin.close();

	return 0;
}
</code></pre>
<p><strong>.csv格式文件读取</strong><br>
和读txt文件相同</p>
<h3 id="12-实例读取tdms格式文件并转化为txt">1.2 实例：读取tdms格式文件并转化为txt</h3>
<p>实例比较难，还没有达到那个水平，希望回头等C++熟练了再做一次</p>
<h2 id="2信号中的一些分析方法实现">2.信号中的一些分析方法实现</h2>
<h3 id="21-傅里叶变换">2.1 傅里叶变换</h3>
<h3 id="22-频谱分析">2.2 频谱分析</h3>
<h3 id="22-功率谱分析">2.2 功率谱分析</h3>
<h2 id="3信号中的常用滤波方法">3.信号中的常用滤波方法</h2>
<h3 id="31-低通滤波">3.1 低通滤波</h3>
<h3 id="32-高通滤波">3.2 高通滤波</h3>
<h3 id="33-带通滤波">3.3 带通滤波</h3>
<h3 id="34-卡尔曼滤波">3.4 卡尔曼滤波</h3>
<h3 id="35-小波分析">3.5 小波分析</h3>
<h2 id="4常用算法实现以及改进">4.常用算法实现以及改进</h2>
<h3 id="41-粒子群优化算法">4.1 粒子群优化算法</h3>
<h3 id="42-遗传算法">4.2 遗传算法</h3>
<h2 id="5opencv基本操作">5.opencv基本操作</h2>
<h2 id="6qt-gui开发">6.QT GUI开发</h2>
<h3 id="61-数据处理软件">6.1 数据处理软件</h3>
<h3 id="62-优秀开源软件">6.2 优秀开源软件</h3>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[【编程】剑指offer刷题笔记]]></title>
        <id>https://currydai.com/post/bian-cheng-jian-zhi-offer-shua-ti-bi-ji/</id>
        <link href="https://currydai.com/post/bian-cheng-jian-zhi-offer-shua-ti-bi-ji/">
        </link>
        <updated>2021-03-13T13:41:50.000Z</updated>
        <content type="html"><![CDATA[<h2 id="1面试的流程">1.面试的流程</h2>
<h3 id="11-小tips">1.1 小Tips</h3>
<ul>
<li>什么都是浮云，应聘技术岗位就是要踏实的写程序</li>
<li>先写单元测试用例，再写解决问题的函数</li>
<li>熟练使用设置断点、单步跟踪、查看内存、分析调用栈</li>
<li>简短的项目背景-&gt;自己完成的任务-&gt;怎么做的-&gt;自己的贡献</li>
<li>扎实的基础知识、能写高质量的代码、分析问题思路清晰、能优化时间和空间效率</li>
<li>扎实的基础知识：编程语言、数据结构和算法</li>
<li>面试官除了希望应聘者的代码能够完成基本的功能，还会关注应聘者是否考虑了边界条件、特殊输入以及错误处理</li>
</ul>
<h2 id="2面试需要的基础知识">2.面试需要的基础知识</h2>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[【转载】什么是C++研发工程师]]></title>
        <id>https://currydai.com/post/zhuan-zai-shi-me-shi-cyan-fa-gong-cheng-shi/</id>
        <link href="https://currydai.com/post/zhuan-zai-shi-me-shi-cyan-fa-gong-cheng-shi/">
        </link>
        <updated>2021-03-13T12:21:59.000Z</updated>
        <content type="html"><![CDATA[<h2 id="1-学习c的意义">1. 学习C++的意义</h2>
<p>在性能方面上，有着无可替代的优势特别是对于很多游戏开发公司来说，C++尤其适合作为后端服务的开发语言。在一些对于并发性能要求较高的业务上，C++也有绝对的优势。因此大部分公司的核心业务都是用C++进行开发，C++工程师掌握着公司最核心最重要的业务体系，有着十分重要的地位。</p>
<h2 id="2-c研发工程师可以从事哪些岗位呢">2. C++研发工程师可以从事哪些岗位呢？</h2>
<ul>
<li>C++服务器程序员：流媒体后台，游戏后台，高性能服务器后台</li>
<li>应用开发工程师windows /linux c++：QT和MFC，偏前端</li>
<li>C++游戏开发：游戏方向，熟悉游戏引擎cocos2dx等</li>
<li>C++逆向开发工程师：网络安全，黑客攻防，破解等</li>
<li>智能硬件和可穿戴设备：C/C++,Linux平台，VR/AR，软硬兼施等</li>
<li>图像处理：机器视觉，医学图像，遥感图像，人像等</li>
</ul>
<h2 id="3-cc工程师该学习哪些内容呢">3. C/C++工程师，该学习哪些内容呢？</h2>
<h3 id="31-玩转c语言">3.1 玩转C语言</h3>
<ul>
<li>数据类型、流程控制、函数、指针</li>
<li>内存布局、结构体、共用体、文件操作</li>
<li>小项目：可以自己设计一个通讯录主要是二级指针，结构体，文件的操作</li>
</ul>
<h3 id="32-c入门">3.2 C++入门</h3>
<h4 id="321-c对c的扩展">3.2.1 C++对C的扩展</h4>
<ul>
<li>C++关键字、命名空间、引用</li>
<li>C/C++混合编程、函数扩展</li>
</ul>
<h4 id="322-c基础">3.2.2 C++基础</h4>
<ul>
<li>面向对象编程思想、类的封装</li>
<li>构造函数、析构函数、静态成员</li>
<li>对象管理、友元函数与友元类</li>
<li>操作符重载、继承与多继承、多态</li>
<li>虚函数与抽象类、函数模板与类模板</li>
<li>智能指针</li>
<li>输入输出流、异常处理</li>
</ul>
<h4 id="323-数据结构">3.2.3 数据结构</h4>
<ul>
<li>算法基础、顺序存储、链式存储</li>
<li>循环链表、双向链表、栈（顺序&amp;链式）</li>
<li>队列（顺序&amp;链式）、树的概念 &amp; 遍历</li>
<li>二叉树、平衡树，搜索树、红黑树</li>
<li>各种排序算法</li>
</ul>
<h3 id="33-c进阶">3.3 C++进阶</h3>
<h4 id="331-stl">3.3.1 STL</h4>
<ul>
<li>序列式容器：堆栈容器、双向链表容器</li>
<li>关联式容器：STL算法详解</li>
</ul>
<h4 id="332-设计模式和uml">3.3.2 设计模式和UML</h4>
<ul>
<li>设计模式概念、面向对象设计原则</li>
<li>单例模式、工厂模式、UML应用</li>
</ul>
<h4 id="333-小项目贪吃蛇">3.3.3 小项目：贪吃蛇</h4>
<ul>
<li>对常用数据结构链表的使用，类额使用</li>
<li>项目开发流程的熟悉</li>
</ul>
<h3 id="34-linux">3.4 Linux</h3>
<h4 id="341-初始linux">3.4.1 初始Linux</h4>
<ul>
<li>Linux操作系统的介绍、Linux目录和路径</li>
<li>Linux文件权限、Linux常用命令</li>
<li>VIM编辑器、websever的环境搭建</li>
</ul>
<h4 id="342-深入理解linux">3.4.2 深入理解Linux</h4>
<ul>
<li>基本操作：运维操作、文件I/O 操作</li>
<li>系统编程:进程控制原理、进程间通信、Linux信号处理</li>
<li>系统编程:进程间关系、守护进程、线程控制原理、线程间同步</li>
<li>网络编程:网络编程协议（TCP/IP、UDP）、Socket套接字原理</li>
<li>网络编程:高并发服务器、异步I/O、Libevent</li>
<li>小项目：web服务器:多进程、多线程、进程间通信,多任务编程、网络数据通信过程,B/S、C/S 网络概念</li>
</ul>
<h3 id="35-数据库知识">3.5 数据库知识</h3>
<ul>
<li>oracle</li>
<li>mysql</li>
<li>MongoDB</li>
</ul>
<h3 id="36-桌面应用开发方向">3.6 桌面应用开发方向</h3>
<ul>
<li>Qt常用的控件</li>
<li>Qt绘图与文件操作</li>
<li>Qt界面编程实战案例</li>
<li>MFC对话框与常用空间</li>
<li>MFC界面编程</li>
</ul>
<h3 id="37-分布式云平台开发">3.7 分布式云平台开发</h3>
<ul>
<li>分布式文件存储服务器和缓存服务器</li>
<li>深入理解nginx</li>
<li>负载均衡反向代理</li>
<li>git</li>
</ul>
<p>作者：Joey Seung<br>
链接：https://zhuanlan.zhihu.com/p/75728337<br>
来源：知乎</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[【编程】python难点整理]]></title>
        <id>https://currydai.com/post/bian-cheng-python-jin-jie-zhi-lu/</id>
        <link href="https://currydai.com/post/bian-cheng-python-jin-jie-zhi-lu/">
        </link>
        <updated>2021-03-08T00:47:57.000Z</updated>
        <content type="html"><![CDATA[<h3 id="1python模块化">1.python模块化</h3>
<h4 id="简单的模块化方式">简单的模块化方式</h4>
<p>可以把函数、类、常量拆分到不同的文件，把它们放在同一个文件夹，然后使用  from your_file import function_name, class_name 的方式调用。之后，这些函数和类就可以在文件内直接使用了</p>
<h4 id="复杂的模块化">复杂的模块化</h4>
<p>main.py 调用子目录的模块时，只需要使用 . 代替 /  来表示子目录，utils.utils 表示 utils 子文件夹下的 utils.py 模块就行。<br>
那如果我们想调用上层目录呢？注意，sys.path.append(&quot;..&quot;) 表示将当前程序所在位置向上提了一级，之后就能调用 utils 的模块了。</p>
<h3 id="2类方法实例方法静态方法的作用和区别">2.类方法，实例方法，静态方法的作用和区别</h3>
<h4 id="实例方法">实例方法</h4>
<p>定义：第一个参数必须是<strong>实例对象</strong>，该参数名一般约定为“self”，通过它来传递实例的属性和方法（也可以传类的属性和方法）。<br>
调用：只能由<strong>实例对象</strong>调用。</p>
<h4 id="类方法">类方法</h4>
<p>定义：使用装饰器@classmethod。第一个参数必须是<strong>当前类对象</strong>，该参数名一般约定为“cls”，通过它来传递类的属性和方法（不能传实例的属性和方法）；<br>
调用：<strong>实例对象和类对象</strong>都可以调用。<br>
举例：<br>
假设我有一个学生类和一个班级类，想要实现的功能为：<br>
执行班级人数增加的操作、获得班级的总人数；<br>
学生类继承自班级类，每实例化一个学生，班级人数都能增加；<br>
最后，我想定义一些学生，获得班级中的总人数。</p>
<pre><code>class ClassTest(object):
    __num = 0

    @classmethod
    def addNum(cls):
        cls.__num += 1

    @classmethod
    def getNum(cls):
        return cls.__num

    # 这里我用到魔术函数__new__，主要是为了在创建实例的时候调用人数累加的函数。
    def __new__(self):
        ClassTest.addNum()
        return super(ClassTest, self).__new__(self)


class Student(ClassTest):
    def __init__(self):
        self.name = ''

a = Student()
b = Student()
print(ClassTest.getNum())
</code></pre>
<h4 id="静态方法">静态方法</h4>
<p>定义：使用装饰器@staticmethod。参数随意，没有“self”和“cls”参数，但是方法体中不能使用类或实例的任何属性和方法；在静态方法中，不会涉及到类中的属性和方法的操作。可以理解为，静态方法是个独立的、单纯的函数，它仅仅托管于某个类的名称空间中，便于使用和维护。<br>
调用：实例对象和类对象都可以调用。<br>
举例：<br>
定义一个关于时间操作的类，其中有一个获取当前时间的函数。</p>
<pre><code>import time

class TimeTest(object):
   def __init__(self, hour, minute, second):
       self.hour = hour
       self.minute = minute
       self.second = second

   @staticmethod
   def showTime():
       return time.strftime(&quot;%H:%M:%S&quot;, time.localtime())


print(TimeTest.showTime())
t = TimeTest(2, 10, 10)
nowTime = t.showTime()
print(nowTime)
</code></pre>
<h3 id="3python对象的比较与拷贝">3.python对象的比较与拷贝</h3>
<p>等于（<mark>）和 is 是 Python 中对象比较常用的两种方式。简单来说，'</mark>'操作符比较对象之间的值是否相等，比如下面的例子，表示比较变量 a 和 b 所指向的值是否相等。<br>
不过，需要注意，对于整型数字来说，以上a is b为 True 的结论，只适用于 -5 到 256 范围内的数字。<br>
<strong>浅拷贝</strong>，是指重新分配一块内存，创建一个新的对象，里面的元素是原对象中子对象的引用。因此，如果原对象中的元素不可变，那倒无所谓；但如果元素可变，浅拷贝通常会带来一些副作用，尤其需要注意。<br>
这个例子中，我们首先初始化了一个列表 l1，里面的元素是一个列表和一个元组；然后对 l1 执行浅拷贝，赋予 l2。因为浅拷贝里的元素是对原对象元素的引用，因此 l2 中的元素和 l1 指向同一个列表和元组对象。接着往下看。l1.append(100)，表示对 l1 的列表新增元素 100。这个操作不会对 l2 产生任何影响，因为 l2 和 l1 作为整体是两个不同的对象，并不共享内存地址。操作过后 l2 不变，l1 会发生改变。再来看，l1[0].append(3)，这里表示对 l1 中的第一个列表新增元素 3。因为 l2 是 l1 的浅拷贝，l2 中的第一个元素和 l1 中的第一个元素，共同指向同一个列表，因此 l2 中的第一个列表也会相对应的新增元素 3。操作后 l1 和 l2 都会改变。<br>
<strong>深度拷贝</strong>，是指重新分配一块内存，创建一个新的对象，并且将原对象中的元素，以递归的方式，通过创建新的子对象拷贝到新对象中。因此，新对象和原对象没有任何关联。我们可以看到，无论 l1 如何变化，l2 都不变。因为此时的 l1 和 l2 完全独立，没有任何联系。</p>
<p>由此可见，在 Python 中：变量的赋值，只是表示让变量指向了某个对象，并不表示拷贝对象给变量；而一个对象，可以被多个变量所指向。可变对象（列表，字典，集合等等）的改变，会影响所有指向该对象的变量。对于不可变对象（字符串、整型、元组等等），所有指向该对象的变量的值总是一样的，也不会改变。但是通过某些操作（+= 等等）更新不可变对象的值时，会返回一个新的对象。变量可以被删除，但是对象无法被删除。</p>
<p>准确地说，Python 的参数传递是赋值传递 （pass by assignment），或者叫作对象的引用传递（pass by object reference）。Python 里所有的数据类型都是对象，所以参数传递时，只是让新变量与原变量指向相同的对象而已，并不存在值传递或是引用传递一说。</p>
<h3 id="4深入理解迭代器和生成器">4.深入理解迭代器和生成器</h3>
<p>在 Python 中一切皆对象，对象的抽象就是类，而对象的集合就是容器。列表（list: [0, 1, 2]），元组（tuple: (0, 1, 2)），字典（dict: {0:0, 1:1, 2:2}），集合（set: set([0, 1, 2])）都是容器。对于容器，你可以很直观地想象成多个元素在一起的单元；而不同容器的区别，正是在于内部数据结构的实现方法。然后，你就可以针对不同场景，选择不同时间和空间复杂度的容器。<br>
所有的容器都是可迭代的（iterable）。而可迭代对象，通过 iter() 函数返回一个迭代器，再通过 next() 函数就可以实现遍历。for in 语句将这个过程隐式化。<br>
生成器是懒人版本的迭代器。</p>
<h3 id="5并发编程">5.并发编程</h3>
<p>协程是实现并发编程的一种方式。</p>
<pre><code>
import asyncio

async def crawl_page(url):
    print('crawling {}'.format(url))
    sleep_time = int(url.split('_')[-1])
    await asyncio.sleep(sleep_time)
    print('OK {}'.format(url))

async def main(urls):
    for url in urls:
        await crawl_page(url)

%time asyncio.run(main(['url_1', 'url_2', 'url_3', 'url_4']))

########## 输出 ##########

crawling url_1
OK url_1
crawling url_2
OK url_2
crawling url_3
OK url_3
crawling url_4
OK url_4
Wall time: 10 s
</code></pre>
<p>首先来看 import asyncio，这个库包含了大部分我们实现协程所需的魔法工具。async 修饰词声明异步函数，于是，这里的 crawl_page 和 main 都变成了异步函数。而调用异步函数，我们便可得到一个协程对象（coroutine object）。<br>
首先你要辨别一个误区，在 Python 中，并发并不是指同一时刻有多个操作（thread、task）同时进行。相反，某个特定的时刻，它只允许有一个操作发生，只不过线程 / 任务之间会互相切换，直到完成。<br>
对比来看，并发通常应用于 I/O 操作频繁的场景，比如你要从网站上下载多个文件，I/O 操作的时间可能会比 CPU 运行处理的时间长得多。并行则更多应用于 CPU heavy 的场景，比如 MapReduce 中的并行计算，为了加快运行速度，一般会用多台机器、多个处理器来完成。</p>
<ul>
<li>同一时刻，Python 主程序只允许有一个线程执行，所以 Python 的并发，是通过多线程的切换完成的。</li>
<li>如果是 I/O bound，并且 I/O 操作很慢，需要很多任务 / 线程协同实现，那么使用 Asyncio 更合适。</li>
<li>如果是 I/O bound，但是 I/O 操作很快，只需要有限数量的任务 / 线程，那么使用多线程就可以了。如果是 CPU bound，则需要使用多进程来提高程序运行效率。</li>
</ul>
<p>CPython 使用引用计数来管理内存，所有 Python 脚本中创建的实例，都会有一个引用计数，来记录有多少个指针指向它。当引用计数只有 0 时，则会自动释放内存。所以说，CPython  引进 GIL 其实主要就是这么两个原因：一是设计者为了规避类似于内存管理这样的复杂的竞争风险问题（race condition）；二是因为 CPython 大量使用 C 语言库，但大部分 C 语言库都不是原生线程安全的（线程安全会降低性能和增加复杂度）。<br>
CPython 中还有另一个机制，叫做 check_interval，意思是 CPython 解释器会去轮询检查线程 GIL 的锁住情况。每隔一段时间，Python 解释器就会强制当前线程去释放 GIL，这样别的线程才能有执行的机会。<br>
如果你的应用真的对性能有超级严格的要求，比如 100us 就对你的应用有很大影响，那我必须要说，Python 可能不是你的最优选择。当然，可以理解的是，我们难以避免的有时候就是想临时给自己松松绑，摆脱 GIL，比如在深度学习应用里，大部分代码就都是 Python 的。在实际工作中，如果我们想实现一个自定义的微分算子，或者是一个特定硬件的加速器，那我们就不得不把这些关键性能（performance-critical）代码在 C++ 中实现（不再受 GIL 所限），然后再提供 Python 的调用接口。<br>
总的来说，你只需要重点记住，绕过 GIL 的大致思路有这么两种就够了：绕过 CPython，使用 JPython（Java 实现的 Python 解释器）等别的实现；把关键性能代码，放到别的语言（一般是 C++）中实现。</p>
<h3 id="6垃圾回收">6.垃圾回收</h3>
<p>我们知道，Python 程序在运行的时候，需要在内存中开辟出一块空间，用于存放运行时产生的临时变量；计算完成后，再将结果输出到永久性存储器中。如果数据量过大，内存空间管理不善就很容易出现 OOM（out of memory），俗称爆内存，程序可能被操作系统中止。<br>
而对于服务器，这种设计为永不中断的系统来说，内存管理则显得更为重要，不然很容易引发内存泄漏。什么是内存泄漏呢？这里的泄漏，并不是说你的内存出现了信息安全问题，被恶意程序利用了，而是指程序本身没有设计好，导致程序未能释放已不再使用的内存。内存泄漏也不是指你的内存在物理上消失了，而是意味着代码在分配了某段内存后，因为设计错误，失去了对这段内存的控制，从而造成了内存的浪费。<br>
我们反复提过好几次， Python 中一切皆对象。因此，你所看到的一切变量，本质上都是对象的一个指针。</p>
<ul>
<li>global a 表示将 a 声明为全局变量。那么，即使函数返回后，列表的引用依然存在，于是对象就不会被垃圾回收掉，依然占用大量内存。</li>
<li>如果我们把生成的列表返回，然后在主程序中接收，那么引用依然存在，垃圾回收就不会被触发，大量内存仍然被占用着<br>
Python 使用标记清除（mark-sweep）算法和分代收集（generational），来启用针对循环引用的自动垃圾回收。你可能不太熟悉这两个词，这里我简单介绍一下。先来看标记清除算法。我们先用图论来理解不可达的概念。对于一个有向图，如果从一个节点出发进行遍历，并标记其经过的所有节点；那么，在遍历结束后，所有没有被标记的节点，我们就称之为不可达节点。显而易见，这些节点的存在是没有任何意义的，自然的，我们就需要对它们进行垃圾回收。当然，每次都遍历全图，对于 Python 而言是一种巨大的性能浪费。所以，在 Python 的垃圾回收实现中，mark-sweep 使用双向链表维护了一个数据结构，并且只考虑容器类的对象（只有容器类对象才有可能产生循环引用）。具体算法这里我就不再多讲了，毕竟我们的重点是关注应用。而分代收集算法，则是另一个优化手段。Python 将所有对象分为三代。刚刚创立的对象是第 0 代；经过一次垃圾回收后，依然存在的对象，便会依次从上一代挪到下一代。而每一代启动自动垃圾回收的阈值，则是可以单独指定的。当垃圾回收器中新增对象减去删除对象达到相应的阈值时，就会对这一代对象启动垃圾回收。事实上，分代收集基于的思想是，新生的对象更有可能被垃圾回收，而存活更久的对象也有更高的概率继续存活。因此，通过这种做法，可以节约不少计算量，从而提高 Python 的性能。学了这么多，刚刚面试官的问题，你应该能回答得上来了吧！没错，引用计数是其中最简单的实现，不过切记，引用计数并非充要条件，它只能算作充分非必要条件；至于其他的可能性，我们所讲的循环引用正是其中一种。<br>
objgraph，一个非常好用的可视化引用关系的包。在这个包中，我主要推荐两个函数，第一个是 show_refs()，它可以生成清晰的引用关系图。通过下面这段代码和生成的引用调用图，你能非常直观地发现，有两个 list 互相引用，说明这里极有可能引起内存泄露。这样一来，再去代码层排查就容易多了。<br>
objgraph.show_refs([a])<br>
objgraph.show_backrefs([a])</li>
</ul>
<h3 id="7python多进程实战">7.python多进程实战</h3>
<p>创建进程的类：Process<br>
Process(group, target , name , args , kwargs)，由该类实例化得到的对象，表示一个子进程中的任务（尚未启动）</p>
<ol>
<li>group参数未使用，值始终为None</li>
<li>target表示调用对象，即子进程要执行的任务</li>
<li>args表示调用对象的位置参数元组，args=(1,2,'anne',)</li>
<li>kwargs表示调用对象的字典,kwargs={'name':'anne','age':18}</li>
<li>name为子进程的名称</li>
</ol>
<p><strong>创建并开启进程的两种方法</strong></p>
<ul>
<li>直接调用</li>
</ul>
<pre><code>#方法一 直接调用import time
import random
from multiprocessing import Process
def run(name):
    print('%s runing' %name)
    time.sleep(random.randrange(1,5))
    print('%s running end' %name)



p1=Process(target=run,args=('anne',)) #必须加,号 
p2=Process(target=run,args=('alice',))
p3=Process(target=run,args=('biantai',))
p4=Process(target=run,args=('haha',))

p1.start()
p2.start()
p3.start()
p4.start()
print('主线程')
</code></pre>
<ul>
<li>继承式调用</li>
</ul>
<pre><code>import time
import random
from multiprocessing import Process


class Run(Process):
    def __init__(self,name):
        super().__init__()
        self.name=name
    def run(self):
        print('%s runing' %self.name)
        time.sleep(random.randrange(1,5))
        print('%s runing end' %self.name)

p1=Run('anne')
p2=Run('alex')
p3=Run('ab')
p4=Run('hey')
p1.start() #start会自动调用run
p2.start()
p3.start()
p4.start()
print('主线程')
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[【机器学习】神经网络与深度学习-邱锡鹏]]></title>
        <id>https://currydai.com/post/ji-qi-xue-xi-shen-jing-wang-luo-yu-shen-du-xue-xi-qiu-xi-peng/</id>
        <link href="https://currydai.com/post/ji-qi-xue-xi-shen-jing-wang-luo-yu-shen-du-xue-xi-qiu-xi-peng/">
        </link>
        <updated>2021-03-06T16:30:06.000Z</updated>
        <content type="html"><![CDATA[<h3 id=""></h3>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[【编程】常用设计模式总结(下)]]></title>
        <id>https://currydai.com/post/bian-cheng-chang-yong-she-ji-mo-shi-zong-jie-xia/</id>
        <link href="https://currydai.com/post/bian-cheng-chang-yong-she-ji-mo-shi-zong-jie-xia/">
        </link>
        <updated>2021-02-23T04:42:12.000Z</updated>
        <content type="html"><![CDATA[<h2 id="1简单工程模式">1.简单工程模式</h2>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[【编程】常用设计模式总结(上)]]></title>
        <id>https://currydai.com/post/bian-cheng-chang-yong-she-ji-mo-shi-zong-jie/</id>
        <link href="https://currydai.com/post/bian-cheng-chang-yong-she-ji-mo-shi-zong-jie/">
        </link>
        <updated>2021-02-23T04:10:50.000Z</updated>
        <content type="html"><![CDATA[<h2 id="1设计模式">1.设计模式</h2>
<p><strong>设计模式主要是为了解决某类重复出现的问题而出现的一套成功或有效的解决方案</strong>，设计模式提供一种讨论软件设计的公共语言，使得熟练设计者的设计经验可以被初学者和其他设计者掌握。设计模式还为软件重构提供了目标。 每个模式都描述了一个在我们的环境中不断出现的问题，然后描述了该问题的解决方案的核心，通过这种方式，我们可以无数次地重用那些已有的成功的解决方案，无须再重复相同的工作。<br>
1991年，四人组GoF（Gang of Four，Erich Gamma、Richard Helm、Ralph Johnson 和 John Vlissides）最早将模式应用于软件工程方法学，他们归纳发表了<strong>23种</strong>在软件开发中使用频率较高的设计模式，<strong>旨在用模式来统一沟通面向对象方法在分析、设计和实现间的鸿沟</strong>，由此，软件设计模式诞生了！<br>
设计模式一般包含模式名称、问题、目的、解决方案、效果等要素：</p>
<ul>
<li>模式名称(Pattern Name)：通过一两个词来描述模式的问题、解决方案和效果，以便更好地理解模式并方便开发人员之间的交流，绝大多数模式都是根据其功能或模式结构来命名的；</li>
<li>问题(Problem)：描述应该在何时使用模式，包含了设计中存在的问题以及问题存在的原因；</li>
<li>解决方案(Solution)：描述一个设计模式的组成成分，以及这些组成成分之间的相互关系，各自的职责和协作方式，通常解决方案通过UML类图和核心代码来进行描述；</li>
<li>效果(Consequences)：描述了模式的优缺点以及在使用模式时应权衡的问题。</li>
</ul>
<p>狭义的设计模式一般分为3大类共计23种（广义上说，随着软件技术的逐步发展，不断有新的设计模式被总结出来并应用到工程实践中），如下表。其中，创建型模式关注对象的创建过程，结构性模式关注如何将现有类或对象组织在一起形成更加强大的结构，行为型模式关注系统中对象之间的交互研究系统在运行时对象之间的相互通信与协作，进一步明确对象的职责。<br>
<img src="https://currydai.com/post-images/1614053718714.png" alt="" loading="lazy"></p>
<p>设计模式是从众多优秀的软件系统中总结出的成功的、能够实现可维护性复用的设计方案，使用这些方案将避免一些重复性工作，高效设计出高质量的软件系统。总的来说，设计模式主要有以下优点：</p>
<p>设计模式融合了众多专家的经验，以一种标准的形式供广大开发人员使用，通俗的设计词汇和通用的语言方便开发人员交流和学习；</p>
<ul>
<li>设计模式使人们可以更简单方便地复用成功的设计，使新开发者更容易理解设计思路；</li>
<li>设计模式使设计方案更加灵活、易于修改；</li>
<li>设计模式的使用将提高软件系统的开发效率和软件质量，节约开发成本；</li>
<li>设计模式有助于初学者深入理解面向对象思想。</li>
</ul>
<h2 id="2uml类图介绍">2.UML类图介绍</h2>
<p>UML-Unified Model Language 统一建模语言，是在开发阶段，说明、可视化、构建和书写一个面向对象软件的开放方法。统一建模语言（UML）是一种模型化语言，通过一系列标准的图形符号来描述系统。一份典型的建模图表通常包含几个块或框，连接线和作为模型附加信息之用的文本。UML类图是用户将所希望描述的事物抽象为类，描述类的内部结构和类之间关系的设计视图。<br>
在UML类图中，常有以下几种关系：泛化(Generalization)、实现(Realization)、关联(Association)、聚合(Aggregation)、组合(Composition)和依赖(Dependency)。按照关系的强弱顺序：泛化≥实现&gt;关联&gt;聚合&gt;组合&gt;依赖。<br>
<img src="https://currydai.com/post-images/1614053957390.png" alt="" loading="lazy"></p>
<h3 id="21-泛化generalization">2.1 泛化(Generalization)</h3>
<figure data-type="image" tabindex="1"><img src="https://currydai.com/post-images/1614054050117.png" alt="" loading="lazy"></figure>
<h3 id="22-实现realization">2.2 实现(Realization)</h3>
<figure data-type="image" tabindex="2"><img src="https://currydai.com/post-images/1614054065855.png" alt="" loading="lazy"></figure>
<h3 id="23-关联association">2.3 关联(Association)</h3>
<p>关联是一种拥有关系（has），一个类可以调用另一个类的公有的属性和方法。在类中以成员变量的方式表示。比如老师有自己的学生，知道学生的姓名学号成绩；学生有自己的老师，也知道老师的姓名和所教的科目。关联分为单向关联、双向关联和自关联。<br>
<img src="https://currydai.com/post-images/1614054217176.png" alt="" loading="lazy"><br>
<img src="https://currydai.com/post-images/1614054223069.png" alt="" loading="lazy"><br>
<img src="https://currydai.com/post-images/1614054227904.png" alt="" loading="lazy"><br>
<img src="https://currydai.com/post-images/1614054256768.png" alt="" loading="lazy"></p>
<h3 id="24-聚合aggregation">2.4 聚合(Aggregation)</h3>
<figure data-type="image" tabindex="3"><img src="https://currydai.com/post-images/1614054304109.png" alt="" loading="lazy"></figure>
<h3 id="25-组合composition">2.5 组合(Composition)</h3>
<figure data-type="image" tabindex="4"><img src="https://currydai.com/post-images/1614054347165.png" alt="" loading="lazy"></figure>
<h3 id="26-依赖dependency">2.6 依赖(Dependency)</h3>
<figure data-type="image" tabindex="5"><img src="https://currydai.com/post-images/1614054384156.png" alt="" loading="lazy"></figure>
<h2 id="3面向对象设计的原则">3.面向对象设计的原则</h2>
<p>设计模式需要遵循基本的软件设计原则。可维护性（Maintainability）和可复用性（Reusability）是衡量软件质量的重要的两个属性：</p>
<ul>
<li>可维护性：软件能够被理解、改正、适应及扩展的难易程度</li>
<li>可复用性：软件能够被复用的难易程度<br>
<strong>面向对象设计的原则是支持可维护性复用</strong>，一方面需要实现设计方案或代码的复用，另一方面要保证系统易于扩展和修改，具有良好的可维护性。面向对象设计原则蕴含在各个设计模式中，是学习设计模式的基石，也是用于评价某个设计模式效果（Consequence）的重要指标。<strong>常见的面向对象设计原则包括：单一职责原则、开闭原则、里氏代换原则、依赖倒转原则、接口隔离原则、合成复用原则、迪米特法则。</strong></li>
</ul>
<h3 id="31-单一职责原则">3.1 单一职责原则</h3>
<p>单一职责原则：<br>
定义1：一个对象应该只包含单一的职责，并且该职责被完整地封装在一个类中。<br>
定义2：就一个类而言，应该仅有一个引起它变化的原因。<br>
解释：<br>
高内聚：内聚是对软件系统中元素职责相关性和集中度的度量。如果元素具有高度相关的职责，除了这些职责内的任务，没有其它过多的工作，那么该元素就具有高内聚性；反之则成为低内聚性。<br>
低耦合：耦合是软件结构中各模块之间相互连接的一种度量，耦合强弱取决于模块间接口的复杂程度、进入或访问一个模块的点以及通过接口的数据。<br>
单一职责原则用于控制类的力度大小。软件设计过程中，如果一个类承担的职责越多，那么它被复用的可能性越小。另一方面，如果一个类承担的职责越多，各个职责耦合在一起，修改其中一个职责可能“牵一发而动全身”。因此，应该将这些职责进行分离，不同的职责封装在不同的类中。</p>
<h3 id="32-开闭原则">3.2 开闭原则</h3>
<p>开闭原则：软件实体应对扩展开放，对修改关闭。<br>
开闭原则指软件实体（一个软件模块、一个由不同类组成的局部结构或一个独立的类） 应该在不修改原有代码的基础上进行扩展。软件设计过程中，需求可能会随时变化，需要根据需求扩展已有的设计。如果原有的设计符合开闭原则，那么扩展起来就比较安全（不会影响原有功能，稳定）和方便（易于扩展）。开闭原则的关键在于抽象化。可以为系统定义一个相对较为稳定的抽象层，将不同的实现行为放到具体的实现层中完成。</p>
<h3 id="33里氏代换原则">3.3里氏代换原则</h3>
<p>历史替换原则：所有引用基类的地方必须能透明地使用其子类的对象。<br>
里氏代换原则的指导意义在于：尽可能地使用基类类型来对对象进行定义，而在运行时再确定子类类型，然后用子类对象替换父类对象。设计时应将父类设计为抽象类或者接口，子类继承父类并实现在父类中声明的方法；运行时子类实例（对象）替换父类实例（对象），可以很方便地扩展系统功能。</p>
<h3 id="34-依赖倒转原则">3.4 依赖倒转原则</h3>
<p>依赖倒转原则：高层模块不应该依赖低层模块，它们都应该依赖抽象。抽象不应该依赖于细节，细节应该依赖于抽象。<br>
依赖倒转原则要求再程序代码中传递参数时，或在关联关系中，尽量引用层次高的出现层类，即使用接口或抽象类来声明变量类型、参数类型声明、方法返回类型声明，以及数据类型转换等，而不要使用具体类来做这些事情。（其实这一点也符合里氏代换原则的指导意义，即对一个方法而言，返回基类的地方一定可以返回子类）。同样，依赖倒转原则设计的关键也在与抽象化设计。</p>
<h3 id="35-接口隔离原则">3.5 接口隔离原则</h3>
<p>接口隔离原则：客户端不应该依赖那些它不需要的接口。<br>
当一个接口太大时，应该将它根据需要分割成多个更细小的接口，每个接口仅承担一个相对独立的角色或功能，使用该接口的客户端仅需知道与之相关的方法即可。 但是，接口不能过小，否则系统中接口太多，不利于维护。一般而言，在接口中仅包含为某一类用户定制的方法即可。</p>
<h3 id="36合成复用原则">3.6合成复用原则</h3>
<p>合成复用原则：优先使用对象组合，而不是通过继承来达到复用的目的。<br>
根据UML类图关系，合成复用原则指导在软件设计时，优先使用关联、聚合和组合关系，尽量少用泛化（继承）。对象组合可以使系统更加灵活（黑箱复用），降低类与类之间的耦合度，一个类的变化尽可能不影响其他类（父类和子类耦合度高不高？）。如果要使用继承，则需考虑里氏代换原则和依赖倒转原则。继承关系会破坏系统的封装性，会将基类的实现细节暴露给子类（白箱复用），如果基类发生改变，那么子类的实现也不得不改变。</p>
<h3 id="37迪米特法则">3.7迪米特法则</h3>
<p>迪米特法则：每一个软件单位对其他单位都只有最少的知识，而且局限于那些与本单位密切相关的软件单位<br>
迪米特法则要求一个软件实体应当尽可能少地与其他实体发生相互作用。如果一个系统负荷迪米特法则，那么当修改其中某一个模块时就会尽量少地影响其他模块。应用迪米特法则可以降低系统的耦合度。在类的设计上应该注意以下几点：在类的划分上应尽量创建松耦合的类，类之间的耦合度越低，越有利于复用；类的结构设计上，每一个类都应该降低其成员变量和成员函数的访问权限。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[【数学】基于Hilbert-Huang变换的去噪算法]]></title>
        <id>https://currydai.com/post/shu-xue-ji-yu-hilbert-huang-bian-huan-de-qu-zao-suan-fa/</id>
        <link href="https://currydai.com/post/shu-xue-ji-yu-hilbert-huang-bian-huan-de-qu-zao-suan-fa/">
        </link>
        <updated>2021-02-22T00:49:46.000Z</updated>
        <content type="html"><![CDATA[<h2 id="1hilbert-huang变换理论">1.<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>H</mi><mi>i</mi><mi>l</mi><mi>b</mi><mi>e</mi><mi>r</mi><mi>t</mi><mo>−</mo><mi>H</mi><mi>u</mi><mi>a</mi><mi>n</mi><mi>g</mi></mrow><annotation encoding="application/x-tex">Hilbert-Huang</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.77777em;vertical-align:-0.08333em;"></span><span class="mord mathdefault" style="margin-right:0.08125em;">H</span><span class="mord mathdefault">i</span><span class="mord mathdefault" style="margin-right:0.01968em;">l</span><span class="mord mathdefault">b</span><span class="mord mathdefault">e</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mord mathdefault">t</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.8777699999999999em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.08125em;">H</span><span class="mord mathdefault">u</span><span class="mord mathdefault">a</span><span class="mord mathdefault">n</span><span class="mord mathdefault" style="margin-right:0.03588em;">g</span></span></span></span>变换理论</h2>
<p><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mo>(</mo><mi>H</mi><mi>i</mi><mi>l</mi><mi>b</mi><mi>e</mi><mi>r</mi><mi>t</mi><mo>−</mo><mi>H</mi><mi>u</mi><mi>a</mi><mi>n</mi><mi>g</mi><mi>T</mi><mi>r</mi><mi>a</mi><mi>n</mi><mi>s</mi><mi>f</mi><mi>o</mi><mi>r</mi><mi>m</mi><mo separator="true">,</mo><mi mathvariant="normal">简</mi><mi mathvariant="normal">称</mi><mi mathvariant="normal">为</mi><mi>H</mi><mi>H</mi><mi>T</mi><mo>)</mo></mrow><annotation encoding="application/x-tex">(Hilbert-Huang Transform,简称为HHT)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.08125em;">H</span><span class="mord mathdefault">i</span><span class="mord mathdefault" style="margin-right:0.01968em;">l</span><span class="mord mathdefault">b</span><span class="mord mathdefault">e</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mord mathdefault">t</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.08125em;">H</span><span class="mord mathdefault">u</span><span class="mord mathdefault">a</span><span class="mord mathdefault">n</span><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="mord mathdefault" style="margin-right:0.13889em;">T</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mord mathdefault">a</span><span class="mord mathdefault">n</span><span class="mord mathdefault">s</span><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="mord mathdefault">o</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mord mathdefault">m</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord cjk_fallback">简</span><span class="mord cjk_fallback">称</span><span class="mord cjk_fallback">为</span><span class="mord mathdefault" style="margin-right:0.08125em;">H</span><span class="mord mathdefault" style="margin-right:0.08125em;">H</span><span class="mord mathdefault" style="margin-right:0.13889em;">T</span><span class="mclose">)</span></span></span></span>，一种处理非线性、非平稳性的一种方法。应用这个方法时需执行两个基本步骤:首先,利用EMD 方法把信号分解成若干个本征模态函数(IMF)；然后对每一步分解得到的IMF 分量进行Hilbert 变换，得到相应谱分析结果，最终对分解得到得IMF 进行筛选、组合，得到重构结果。<br>
在理解希尔伯特-黄变换之前首先需要清除一下几个概念：</p>
<ul>
<li>
<p><strong>什么是傅里叶级数</strong><br>
首先傅立叶级数是针对周期函数的，就是通过三角函数和常数项来叠加逼近周期T为函数<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>f</mi><mo>(</mo><mi>x</mi><mo>)</mo></mrow><annotation encoding="application/x-tex">f(x)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mclose">)</span></span></span></span> ：</p>
<p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>f</mi><mo>(</mo><mi>x</mi><mo>)</mo><mo>=</mo><msub><mi>a</mi><mn>0</mn></msub><mo>+</mo><munderover><mo>∑</mo><mrow><mi>n</mi><mo>=</mo><mn>1</mn></mrow><mi mathvariant="normal">∞</mi></munderover><mrow><mo>(</mo><msub><mi>a</mi><mi>n</mi></msub><mi>c</mi><mi>o</mi><mi>s</mi><mo>(</mo><mfrac><mrow><mn>2</mn><mi>π</mi><mi>n</mi></mrow><mi>T</mi></mfrac><mi>x</mi><mo>)</mo><mo>+</mo><msub><mi>b</mi><mi>n</mi></msub><mi>s</mi><mi>i</mi><mi>n</mi><mo>(</mo><mfrac><mrow><mn>2</mn><mi>π</mi><mi>n</mi></mrow><mi>T</mi></mfrac><mi>x</mi><mo>)</mo><mo>)</mo></mrow></mrow><annotation encoding="application/x-tex">f(x)=a_0+\sum _{n=1}^{∞}{(a_ncos(\frac {2 \pi n}{T}x)+b_nsin(\frac {2 \pi n}{T}x))}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.73333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:2.9185100000000004em;vertical-align:-1.267113em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.6513970000000002em;"><span style="top:-1.882887em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">n</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.050005em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3000050000000005em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">∞</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.267113em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord mathdefault">c</span><span class="mord mathdefault">o</span><span class="mord mathdefault">s</span><span class="mopen">(</span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.32144em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">T</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">2</span><span class="mord mathdefault" style="margin-right:0.03588em;">π</span><span class="mord mathdefault">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mord mathdefault">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord"><span class="mord mathdefault">b</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord mathdefault">s</span><span class="mord mathdefault">i</span><span class="mord mathdefault">n</span><span class="mopen">(</span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.32144em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">T</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">2</span><span class="mord mathdefault" style="margin-right:0.03588em;">π</span><span class="mord mathdefault">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mord mathdefault">x</span><span class="mclose">)</span><span class="mclose">)</span></span></span></span></span></span></p>
<p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mi>e</mi><mrow><mi>i</mi><mi>x</mi></mrow></msup><mo>=</mo><mi>c</mi><mi>o</mi><mi>s</mi><mo>(</mo><mi>x</mi><mo>)</mo><mo>+</mo><mi>i</mi><mi>s</mi><mi>i</mi><mi>n</mi><mo>(</mo><mi>x</mi><mo>)</mo></mrow><annotation encoding="application/x-tex">e^{ix}=cos(x)+isin(x)
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8746639999999999em;vertical-align:0em;"></span><span class="mord"><span class="mord mathdefault">e</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8746639999999999em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="mord mathdefault mtight">x</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault">c</span><span class="mord mathdefault">o</span><span class="mord mathdefault">s</span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault">i</span><span class="mord mathdefault">s</span><span class="mord mathdefault">i</span><span class="mord mathdefault">n</span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mclose">)</span></span></span></span></span></p>
<p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>f</mi><mo>(</mo><mi>x</mi><mo>)</mo><mo>=</mo><munderover><mo>∑</mo><mrow><mi>n</mi><mo>=</mo><mo>−</mo><mi mathvariant="normal">∞</mi></mrow><mi mathvariant="normal">∞</mi></munderover><mrow><msub><mi>c</mi><mi>n</mi></msub><mo separator="true">⋅</mo><msup><mi>e</mi><mrow><mi>i</mi><mfrac><mrow><mn>2</mn><mi>π</mi><mi>n</mi><mi>x</mi></mrow><mi>T</mi></mfrac></mrow></msup></mrow></mrow><annotation encoding="application/x-tex">f(x)=\sum _{n=-∞} ^{∞}{c_n·e^{i\frac {2 \pi nx}{T}}}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.959733em;vertical-align:-1.308336em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.6513970000000002em;"><span style="top:-1.8999949999999999em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">n</span><span class="mrel mtight">=</span><span class="mord mtight">−</span><span class="mord mtight">∞</span></span></span></span><span style="top:-3.050005em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3000050000000005em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">∞</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.308336em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord"><span class="mord mathdefault">c</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">⋅</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">e</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:1.0040200000000001em;"><span style="top:-3.4130000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="mord mtight"><span class="mopen nulldelimiter sizing reset-size3 size6"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8443142857142858em;"><span style="top:-2.656em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.13889em;">T</span></span></span></span><span style="top:-3.2255000000000003em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line mtight" style="border-bottom-width:0.049em;"></span></span><span style="top:-3.384em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">2</span><span class="mord mathdefault mtight" style="margin-right:0.03588em;">π</span><span class="mord mathdefault mtight">n</span><span class="mord mathdefault mtight">x</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.344em;"><span></span></span></span></span></span><span class="mclose nulldelimiter sizing reset-size3 size6"></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></p>
<p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>c</mi><mi>n</mi></msub><mo>=</mo><mfrac><mn>1</mn><mi>T</mi></mfrac><msubsup><mo>∫</mo><msub><mi>x</mi><mn>0</mn></msub><mrow><msub><mi>x</mi><mn>0</mn></msub><mo>+</mo><mi>T</mi></mrow></msubsup><mrow><mi>f</mi><mo>(</mo><mi>x</mi><mo>)</mo><mo separator="true">⋅</mo><msup><mi>e</mi><mrow><mo>−</mo><mi>i</mi><mfrac><mrow><mn>2</mn><mi>π</mi><mi>n</mi><mi>x</mi></mrow><mi>T</mi></mfrac></mrow></msup><mi>d</mi><mi>x</mi></mrow></mrow><annotation encoding="application/x-tex">c_n=\frac {1}{T} \int _{x_0}^{x_0+T}{f(x)·e^{-i\frac {2 \pi nx}{T}}dx}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">c</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.603281em;vertical-align:-1.01205em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.32144em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">T</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop"><span class="mop op-symbol large-op" style="margin-right:0.44445em;position:relative;top:-0.0011249999999999316em;">∫</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.5912310000000003em;"><span style="top:-1.7880500000000004em;margin-left:-0.44445em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathdefault mtight">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31731428571428577em;"><span style="top:-2.357em;margin-left:0em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span></span></span></span><span style="top:-3.8129000000000004em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathdefault mtight">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31731428571428577em;"><span style="top:-2.357em;margin-left:0em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span><span class="mbin mtight">+</span><span class="mord mathdefault mtight" style="margin-right:0.13889em;">T</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.01205em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mclose">)</span><span class="mpunct">⋅</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">e</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:1.0040200000000001em;"><span style="top:-3.4130000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span><span class="mord mathdefault mtight">i</span><span class="mord mtight"><span class="mopen nulldelimiter sizing reset-size3 size6"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8443142857142858em;"><span style="top:-2.656em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.13889em;">T</span></span></span></span><span style="top:-3.2255000000000003em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line mtight" style="border-bottom-width:0.049em;"></span></span><span style="top:-3.384em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">2</span><span class="mord mathdefault mtight" style="margin-right:0.03588em;">π</span><span class="mord mathdefault mtight">n</span><span class="mord mathdefault mtight">x</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.344em;"><span></span></span></span></span></span><span class="mclose nulldelimiter sizing reset-size3 size6"></span></span></span></span></span></span></span></span></span></span><span class="mord mathdefault">d</span><span class="mord mathdefault">x</span></span></span></span></span></span></p>
<p>解释：<strong>对于任意周期函数都可以有(常数项，{sin(nx),cos{nx})表示</strong>，因此对于周期函数傅里叶级数中对应的<strong>频谱都是离散的，无穷的</strong>。三角函数的一大特点是不同频率的正弦和余弦都是彼此正交的，也就是一个三角函数和其它的三角函数内积为0。</p>
</li>
<li>
<p><strong>什么是傅里叶变换</strong><br>
首先针对非周期函数，也是通过三角函数逼近非周期信号f(x)，可以视为周期是无穷大的。</p>
</li>
</ul>
<p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>w</mi><mo>=</mo><mfrac><mrow><mn>2</mn><mi>π</mi><mi>n</mi></mrow><mi>T</mi></mfrac></mrow><annotation encoding="application/x-tex">w=\frac {2 \pi n}{T}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.02691em;">w</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.00744em;vertical-align:-0.686em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.32144em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">T</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">2</span><span class="mord mathdefault" style="margin-right:0.03588em;">π</span><span class="mord mathdefault">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></p>
<p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>f</mi><mo>(</mo><mi>x</mi><mo>)</mo><mo>=</mo><msubsup><mo>∫</mo><mrow><mo>−</mo><mi mathvariant="normal">∞</mi></mrow><mrow><mo>+</mo><mi mathvariant="normal">∞</mi></mrow></msubsup><mrow><mi>F</mi><mo>(</mo><mi>w</mi><mo>)</mo><mo separator="true">⋅</mo><msup><mi>e</mi><mrow><mi>i</mi><mi>w</mi><mi>x</mi></mrow></msup><mi>d</mi><mi>w</mi></mrow></mrow><annotation encoding="application/x-tex">f(x)=\int _{-∞}^{+∞}{F(w)·e^{iwx}dw}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.491512em;vertical-align:-0.970281em;"></span><span class="mop"><span class="mop op-symbol large-op" style="margin-right:0.44445em;position:relative;top:-0.0011249999999999316em;">∫</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.5212310000000002em;"><span style="top:-1.7880500000000001em;margin-left:-0.44445em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span><span class="mord mtight">∞</span></span></span></span><span style="top:-3.8129000000000004em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">+</span><span class="mord mtight">∞</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.970281em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">F</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.02691em;">w</span><span class="mclose">)</span><span class="mpunct">⋅</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">e</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8746639999999999em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="mord mathdefault mtight" style="margin-right:0.02691em;">w</span><span class="mord mathdefault mtight">x</span></span></span></span></span></span></span></span></span><span class="mord mathdefault">d</span><span class="mord mathdefault" style="margin-right:0.02691em;">w</span></span></span></span></span></span></p>
<p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>F</mi><mo>(</mo><mi>w</mi><mo>)</mo><mo>=</mo><mfrac><mn>1</mn><mrow><mn>2</mn><mi>π</mi></mrow></mfrac><msubsup><mo>∫</mo><mrow><mo>−</mo><mi mathvariant="normal">∞</mi></mrow><mrow><mo>+</mo><mi mathvariant="normal">∞</mi></mrow></msubsup><mrow><mi>f</mi><mo>(</mo><mi>x</mi><mo>)</mo><mo separator="true">⋅</mo><msup><mi>e</mi><mrow><mo>−</mo><mi>i</mi><mi>w</mi><mi>x</mi></mrow></msup><mi>d</mi><mi>x</mi></mrow></mrow><annotation encoding="application/x-tex">F(w)=\frac {1}{2 \pi}\int _{-∞}^{+∞}{f(x)·e^{-iwx}dx}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">F</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.02691em;">w</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.491512em;vertical-align:-0.970281em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.32144em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">2</span><span class="mord mathdefault" style="margin-right:0.03588em;">π</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop"><span class="mop op-symbol large-op" style="margin-right:0.44445em;position:relative;top:-0.0011249999999999316em;">∫</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.5212310000000002em;"><span style="top:-1.7880500000000001em;margin-left:-0.44445em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span><span class="mord mtight">∞</span></span></span></span><span style="top:-3.8129000000000004em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">+</span><span class="mord mtight">∞</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.970281em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mclose">)</span><span class="mpunct">⋅</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">e</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.874664em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span><span class="mord mathdefault mtight">i</span><span class="mord mathdefault mtight" style="margin-right:0.02691em;">w</span><span class="mord mathdefault mtight">x</span></span></span></span></span></span></span></span></span><span class="mord mathdefault">d</span><span class="mord mathdefault">x</span></span></span></span></span></span></p>
<p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>f</mi><mo>(</mo><mi>x</mi><mo>)</mo><mo>&lt;</mo><mo>−</mo><mo>&gt;</mo><mi>F</mi><mo>(</mo><mi>w</mi><mo>)</mo></mrow><annotation encoding="application/x-tex">f(x)&lt;-&gt;F(w)
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">&lt;</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.66666em;vertical-align:-0.08333em;"></span><span class="mord">−</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">&gt;</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">F</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.02691em;">w</span><span class="mclose">)</span></span></span></span></span></p>
<p>解释：<strong>对于任意非周期函数都可以有(常数项，{sin(nx),cos{nx})表示</strong>，但是此时需要无限稠密的周期三角函数基去逼近。因此对于非周期函数傅里叶变换中对应的<strong>频谱都是连续的，无穷的</strong>。</p>
<ul>
<li><strong>什么是卷积</strong><br>
频域是时域整体的表达,频域上信号的一个点,对应的是整个时域信号该对应频率的信息,因此,在频域中的乘法,自然就对应了时域整段所有不同频率信号乘法的叠加,这就是卷积。</li>
</ul>
<p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>f</mi><mo>(</mo><mi>t</mi><mo>)</mo><mo>∗</mo><mi>g</mi><mo>(</mo><mi>t</mi><mo>)</mo><mo>=</mo><msubsup><mo>∫</mo><mrow><mo>−</mo><mi mathvariant="normal">∞</mi></mrow><mrow><mo>+</mo><mi mathvariant="normal">∞</mi></mrow></msubsup><mrow><mi>f</mi><mo>(</mo><mi>τ</mi><mo>)</mo><mo>∗</mo><mi>g</mi><mo>(</mo><mi>y</mi><mo>−</mo><mi>τ</mi><mo>)</mo><mi>d</mi><mi>τ</mi></mrow></mrow><annotation encoding="application/x-tex">f(t)*g(t)=\int _{-∞}^{+∞}{f(\tau)*g(y- \tau)d \tau}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord mathdefault">t</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="mopen">(</span><span class="mord mathdefault">t</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.491512em;vertical-align:-0.970281em;"></span><span class="mop"><span class="mop op-symbol large-op" style="margin-right:0.44445em;position:relative;top:-0.0011249999999999316em;">∫</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.5212310000000002em;"><span style="top:-1.7880500000000001em;margin-left:-0.44445em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span><span class="mord mtight">∞</span></span></span></span><span style="top:-3.8129000000000004em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">+</span><span class="mord mtight">∞</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.970281em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.1132em;">τ</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord mathdefault" style="margin-right:0.1132em;">τ</span><span class="mclose">)</span><span class="mord mathdefault">d</span><span class="mord mathdefault" style="margin-right:0.1132em;">τ</span></span></span></span></span></span></p>
<p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>F</mi><mo>[</mo><mi>f</mi><mo>(</mo><mi>t</mi><mo>)</mo><mo>∗</mo><mi>g</mi><mo>(</mo><mi>t</mi><mo>)</mo><mo>]</mo><mo>=</mo><msubsup><mo>∫</mo><mrow><mo>−</mo><mi mathvariant="normal">∞</mi></mrow><mrow><mo>+</mo><mi mathvariant="normal">∞</mi></mrow></msubsup><mo>[</mo><msubsup><mo>∫</mo><mrow><mo>−</mo><mi mathvariant="normal">∞</mi></mrow><mrow><mo>+</mo><mi mathvariant="normal">∞</mi></mrow></msubsup><mrow><mi>f</mi><mo>(</mo><mi>τ</mi><mo>)</mo><mo>∗</mo><mi>g</mi><mo>(</mo><mi>y</mi><mo>−</mo><mi>τ</mi><mo>)</mo><mi>d</mi><mi>τ</mi></mrow><mo>]</mo><msup><mi>e</mi><mrow><mo>−</mo><mi>j</mi><mi>w</mi><mi>t</mi><mi>d</mi><mi>t</mi></mrow></msup><mo>=</mo><msub><mi>F</mi><mn>1</mn></msub><mo>(</mo><mi>w</mi><mo>)</mo><msub><mi>F</mi><mn>2</mn></msub><mo>(</mo><mi>w</mi><mo>)</mo></mrow><annotation encoding="application/x-tex">F[f(t)*g(t)]=\int _{-∞}^{+∞}[\int _{-∞}^{+∞}{f(\tau)*g(y- \tau)d \tau}]e^{-jwtdt}=F_1(w)F_2(w)
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">F</span><span class="mopen">[</span><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord mathdefault">t</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="mopen">(</span><span class="mord mathdefault">t</span><span class="mclose">)</span><span class="mclose">]</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.491512em;vertical-align:-0.970281em;"></span><span class="mop"><span class="mop op-symbol large-op" style="margin-right:0.44445em;position:relative;top:-0.0011249999999999316em;">∫</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.5212310000000002em;"><span style="top:-1.7880500000000001em;margin-left:-0.44445em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span><span class="mord mtight">∞</span></span></span></span><span style="top:-3.8129000000000004em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">+</span><span class="mord mtight">∞</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.970281em;"><span></span></span></span></span></span></span><span class="mopen">[</span><span class="mop"><span class="mop op-symbol large-op" style="margin-right:0.44445em;position:relative;top:-0.0011249999999999316em;">∫</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.5212310000000002em;"><span style="top:-1.7880500000000001em;margin-left:-0.44445em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span><span class="mord mtight">∞</span></span></span></span><span style="top:-3.8129000000000004em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">+</span><span class="mord mtight">∞</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.970281em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.1132em;">τ</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord mathdefault" style="margin-right:0.1132em;">τ</span><span class="mclose">)</span><span class="mord mathdefault">d</span><span class="mord mathdefault" style="margin-right:0.1132em;">τ</span></span><span class="mclose">]</span><span class="mord"><span class="mord mathdefault">e</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8991079999999999em;"><span style="top:-3.1130000000000004em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span><span class="mord mathdefault mtight" style="margin-right:0.02691em;">w</span><span class="mord mathdefault mtight">t</span><span class="mord mathdefault mtight">d</span><span class="mord mathdefault mtight">t</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">F</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.02691em;">w</span><span class="mclose">)</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">F</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.02691em;">w</span><span class="mclose">)</span></span></span></span></span></p>
<p>注意CNN中卷积：CNN中卷积层拿输入和卷积核做卷积和计算其实就是二维离散卷积的分段卷积和计算法。之所以采用这种算法是因为把输入看多f(n)，卷积核看作g(m)，m&lt;&lt;n，这样的算法具有较小的计算复杂度。另外所谓少了旋转的步骤，这是二维卷积的基本性质，你用的卷积核本身的对称性，使得旋转不旋转都是一样的。</p>
<ul>
<li><strong>什么是拉普拉斯变换</strong><br>
狄利赫里条件：函数在任意有限区间连续或者只有有限个第一类间断点；在一个周期内，函数有有限个极大值和极小值；函数是绝对可积的。<br>
对于不满足狄利赫里条件的<strong>连续信号</strong>的拉普拉斯变换与逆变换：</li>
</ul>
<p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>F</mi><mo>(</mo><mi>s</mi><mo>)</mo><mo>=</mo><msubsup><mo>∫</mo><mrow><mo>−</mo><mi mathvariant="normal">∞</mi></mrow><mrow><mo>+</mo><mi mathvariant="normal">∞</mi></mrow></msubsup><mrow><mi>f</mi><mo>(</mo><mi>t</mi><mo>)</mo><msup><mi>e</mi><mrow><mo>−</mo><mi>s</mi><mi>t</mi></mrow></msup><mi>d</mi><mi>t</mi></mrow></mrow><annotation encoding="application/x-tex">F(s)=\int _{-∞}^{+∞}{f(t)e^{-st}dt}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">F</span><span class="mopen">(</span><span class="mord mathdefault">s</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.491512em;vertical-align:-0.970281em;"></span><span class="mop"><span class="mop op-symbol large-op" style="margin-right:0.44445em;position:relative;top:-0.0011249999999999316em;">∫</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.5212310000000002em;"><span style="top:-1.7880500000000001em;margin-left:-0.44445em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span><span class="mord mtight">∞</span></span></span></span><span style="top:-3.8129000000000004em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">+</span><span class="mord mtight">∞</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.970281em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord mathdefault">t</span><span class="mclose">)</span><span class="mord"><span class="mord mathdefault">e</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.843556em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span><span class="mord mathdefault mtight">s</span><span class="mord mathdefault mtight">t</span></span></span></span></span></span></span></span></span><span class="mord mathdefault">d</span><span class="mord mathdefault">t</span></span></span></span></span></span></p>
<p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>f</mi><mo>(</mo><mi>t</mi><mo>)</mo><mo>=</mo><mfrac><mn>1</mn><mrow><mn>2</mn><mi>π</mi><mi>j</mi></mrow></mfrac><msubsup><mo>∫</mo><mrow><mi>σ</mi><mo>−</mo><mi>j</mi><mi mathvariant="normal">∞</mi></mrow><mrow><mi>σ</mi><mo>+</mo><mi>j</mi><mi mathvariant="normal">∞</mi></mrow></msubsup><mrow><mi>F</mi><mo>(</mo><mi>s</mi><mo>)</mo><msup><mi>e</mi><mrow><mi>s</mi><mi>t</mi></mrow></msup><mi>d</mi><mi>s</mi></mrow></mrow><annotation encoding="application/x-tex">f(t)={\frac {1}{2 \pi j}}\int _{\sigma-j∞}^{\sigma+j∞}{F(s)e^{st}ds}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord mathdefault">t</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.622622em;vertical-align:-1.048058em;"></span><span class="mord"><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.32144em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">2</span><span class="mord mathdefault" style="margin-right:0.03588em;">π</span><span class="mord mathdefault" style="margin-right:0.05724em;">j</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.8804400000000001em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop"><span class="mop op-symbol large-op" style="margin-right:0.44445em;position:relative;top:-0.0011249999999999316em;">∫</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.5745639999999999em;"><span style="top:-1.7880500000000001em;margin-left:-0.44445em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.03588em;">σ</span><span class="mbin mtight">−</span><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span><span class="mord mtight">∞</span></span></span></span><span style="top:-3.8129em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.03588em;">σ</span><span class="mbin mtight">+</span><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span><span class="mord mtight">∞</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.048058em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">F</span><span class="mopen">(</span><span class="mord mathdefault">s</span><span class="mclose">)</span><span class="mord"><span class="mord mathdefault">e</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.843556em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">s</span><span class="mord mathdefault mtight">t</span></span></span></span></span></span></span></span></span><span class="mord mathdefault">d</span><span class="mord mathdefault">s</span></span></span></span></span></span></p>
<p>理解：把不能变换的信号乘以一个衰减因子<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mi>e</mi><mrow><mo>−</mo><mi>σ</mi><mi>t</mi></mrow></msup></mrow><annotation encoding="application/x-tex">e^{- \sigma t}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7935559999999999em;vertical-align:0em;"></span><span class="mord"><span class="mord mathdefault">e</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7935559999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span><span class="mord mathdefault mtight" style="margin-right:0.03588em;">σ</span><span class="mord mathdefault mtight">t</span></span></span></span></span></span></span></span></span></span></span></span>,先把信号巡抚就可以傅里叶变换了；把复指数信号乘以方法因子<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mi>e</mi><mrow><mi>σ</mi><mi>t</mi></mrow></msup></mrow><annotation encoding="application/x-tex">e^{ \sigma t}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7935559999999999em;vertical-align:0em;"></span><span class="mord"><span class="mord mathdefault">e</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7935559999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.03588em;">σ</span><span class="mord mathdefault mtight">t</span></span></span></span></span></span></span></span></span></span></span></span>，让它追上要变换的信号。<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>σ</mi><mo>=</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">\sigma=0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">σ</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">0</span></span></span></span>就是普通的傅里叶变换。</p>
<ul>
<li>
<p><strong>什么是Z变换</strong><br>
首先出现离散信号的傅里叶变换方法。包括：离散时间傅里叶级数DFS，离散时间傅里叶变换DTFT，离散傅里叶变换DFT，快速傅里叶变换FFT。<br>
然后针对不能变换的数字信号先收敛以后再进行离散傅里叶变换，成为Z变换。是不是和拉普拉斯变换有异曲同工之妙。拉普拉斯变换是对于连续的模拟信号，z变换对应的是离散的数字信号。<br>
<img src="https://currydai.com/post-images/1614040916938.png" alt="" loading="lazy"><br>
Z变换的作用：</p>
<ul>
<li>系统的频率响应-绘图法</li>
<li>数字滤波器原理</li>
</ul>
</li>
<li>
<p><strong>总结：</strong><br>
<img src="https://currydai.com/post-images/1614042053510.png" alt="" loading="lazy"></p>
</li>
<li>
<p><strong>什么是希尔伯特变换</strong><br>
<img src="https://currydai.com/post-images/1614042335121.png" alt="" loading="lazy"><br>
<img src="https://currydai.com/post-images/1614042341475.png" alt="" loading="lazy"><br>
上面的Hilbert变换的表达式实际上就是将原始信号和一个信号做卷积的结果。</p>
</li>
</ul>
<p>理解：</p>
<ul>
<li>局部估计就是考虑信号局部，或是很小的一段区间，全局估计就是需要整个测量，而我们本文提到的Hilbert变换是一个典型的全局方法。</li>
<li>HT等价一个特殊的线性滤波器，所有的频谱幅度均没有变化，知识香味平移了<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mo>−</mo><mfrac><mi>π</mi><mn>2</mn></mfrac></mrow><annotation encoding="application/x-tex">- \frac {\pi}{2}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.040392em;vertical-align:-0.345em;"></span><span class="mord">−</span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.695392em;"><span style="top:-2.6550000000000002em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.03588em;">π</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span>,因此四次变换后与原信号功率相等。并且Sin函数的HT是Cos，Cos的HT是-Sin。</li>
<li>如果一个复信号的实部和虚部为一对HT变换对，我们称这个信号为解析信号。</li>
<li>将复数形式的解析信号可以通过一定变换返回到实信号，成为瞬时信号</li>
<li>适用条件：窄带信号、不含噪声，不是复杂信号，不出现尖峰跳跃，数据尽量平稳，没有“骑波”，避免不可解释的负频率出现等等<br>
<img src="https://currydai.com/post-images/1614043041589.png" alt="" loading="lazy"><br>
<img src="https://currydai.com/post-images/1614042909333.png" alt="" loading="lazy"></li>
</ul>
<ul>
<li>
<p><strong>固有模态函数IMF</strong><br>
对于初始信号，其往往信号比较复杂，包含多种频率成分，如果将每种成分看成单一体（IMF），从而可以理解成信号是由多个固有模态函数（IMF)或者本征模态函数组成的 。<br>
Huang 给出了固有模态函数的定义。一个固有模态函数需要满足以下两个条件函数：<br>
(1)在整个数据序列中,极值点的数量与过零点的数量必须相等,或最多相差不能多于一个。<br>
(2)在任一时间点上,信号的局部极大值和局部极小值定义的包络平均值为零。<br>
采用本征模态函数(IMF）一方面很好的表达了信号数据中的振荡模式。另一方面IMF 是一个单一的、没有其它叠加波的成分在其中。</p>
</li>
<li>
<p><strong>经验模态分解EMD</strong><br>
经验模态分解（EMD）是一个不断摔选的过程，根据设定条件不断剥离、分解,从而得到单个IMF 的过程，也称为筛选过程( The Sifting Process)。,1998 年N.E.Huang 及其同事提出了较为完整的Hilbert-Huang 变换法。<br>
EMD 分解方法相对于小波分析，具有独特优点，无需要选择小波基，其自身能够自动适应每一步分解过程。<br>
分解过程基于以下假设:（1）对信号进行识别与统计极值点数量（最少都存在一个极大与极小值）;(2)时域特性由极值间隔决定;(3)如果数据序列完全缺乏极值但是仅包含拐点,那么它也可通过求导一次或多次来揭示极值点,而最终结果可以由这些成分求积分来获得。<br>
<img src="https://currydai.com/post-images/1614043672661.png" alt="" loading="lazy"><br>
<img src="https://currydai.com/post-images/1614043858212.png" alt="" loading="lazy"></p>
</li>
</ul>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[【编程实战】利用C++完成走迷宫问题]]></title>
        <id>https://currydai.com/post/bian-cheng-shi-zhan-li-yong-cwan-cheng-zou-mi-gong-wen-ti/</id>
        <link href="https://currydai.com/post/bian-cheng-shi-zhan-li-yong-cwan-cheng-zou-mi-gong-wen-ti/">
        </link>
        <updated>2021-02-21T06:37:25.000Z</updated>
        <content type="html"><![CDATA[<h1 id=""></h1>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[【编程】[C++]对象指针vs对象成员vs对象成员指针]]></title>
        <id>https://currydai.com/post/program-cdui-xiang-zhi-zhen-vs-dui-xiang-cheng-yuan-vs-dui-xiang-cheng-yuan-zhi-zhen/</id>
        <link href="https://currydai.com/post/program-cdui-xiang-zhi-zhen-vs-dui-xiang-cheng-yuan-vs-dui-xiang-cheng-yuan-zhi-zhen/">
        </link>
        <updated>2021-02-20T09:49:16.000Z</updated>
        <content type="html"><![CDATA[<h2 id="1背景知识介绍">1.背景知识介绍</h2>
<h3 id="11-类与对象">1.1 类与对象</h3>
<ul>
<li>实例化对象的两种方法：在栈中实例化(自动释放内存)以及在堆中实例化(需要手动释放内存)，需要进一步掌握不同对象访问成员数据以及成员函数的方法</li>
<li>构造函数重要意义：对类成员变量完成初始化赋值操作，对象有了空间和生命</li>
<li>构造函数初始化两种方法：初始化成员列表以及在构造函数内部进行赋值完成，第一种在构造函数体内实现的“=”操作的本质是赋值（Assign）操作，而第二种才是真正的初始化（Initialization），在大部分情况下两者方法可以互用，但是在特殊情况不能互用。
<ul>
<li>const 成员变量只能用初始化列表来完成初始化，而不能在构造函数中被赋值</li>
<li>如果类 B 中含有 A 类型的成员变量，而A类中又禁止了赋值操作，此时要想顺利完成B中成员变量的初始化，就必须采用初始化列表方式。<br>
<strong>总之，在 Class 中成员变量初始化是一个不可或缺的步骤；在初始化成员变量时，出于对方法的通用性及高效性的考虑，强烈推荐采用成员变量初始化列表的方式初始化变量，并且要保证成员变量声明的顺序和初始化列表的顺序一致。</strong></li>
</ul>
</li>
</ul>
<pre><code>#include&lt;iostream&gt;
using namespace std;

class Coordinate
{
public:
	Coordinate(int x, int y); //构造函数
	~Coordinate(); //析构函数
	int getX();
	int getY();
private:
	int m_iX;
	int m_iY;
};

//类外定义方法
Coordinate::Coordinate(int x, int y)
{
	m_iX = x;
	m_iY = y;
	cout &lt;&lt; &quot;Coordinate()    &quot; &lt;&lt; m_iX &lt;&lt; &quot;,&quot; &lt;&lt; m_iY &lt;&lt; endl;
}

Coordinate::~Coordinate()
{
	cout &lt;&lt; &quot;~Coordinate()    &quot; &lt;&lt; m_iX &lt;&lt; &quot;,&quot; &lt;&lt; m_iY &lt;&lt; endl;
}

int Coordinate::getX()
{
	return m_iX;
}

int Coordinate::getY()
{
	return m_iY;
}

int main()
{
	/*
	Coordinate* p = new Coordinate(1, 2); //从堆中实例化对象
	cout &lt;&lt; p-&gt;getX() &lt;&lt; endl;
	cout &lt;&lt; p-&gt;getY() &lt;&lt; endl;
	delete p;
	p = NULL;
	*/

	Coordinate coord(1, 2);//从栈中实例化对象
	cout &lt;&lt; coord.getX() &lt;&lt; endl;
	cout &lt;&lt; coord.getY() &lt;&lt; endl;
}
</code></pre>
<h3 id="12-对象指针vs对象成员vs对象成员指针">1.2 对象指针vs对象成员vs对象成员指针</h3>
<ul>
<li>对象指针：有一个指针，其指向一个对象，典型例子就是在堆中实例化对象就是利用的对象指针。</li>
<li>对象成员：作为一个对象来说，它成为了另外一个类的数据成员<br>
举例说明：<br>
1.Coordinate.cpp定义</li>
</ul>
<pre><code>#include&lt;iostream&gt;
#include&quot;Coordinate.h&quot;
using namespace std;

class Coordinate
{
public:
   Coordinate(int x, int y);
   ~Coordinate();
   int getX();
   int getY();
private:
   int m_iX;
   int m_iY;
};

Coordinate::Coordinate(int x, int y)
{
   m_iX = x;
   m_iY = y;
   cout &lt;&lt; &quot;Coordinate()    &quot; &lt;&lt; m_iX &lt;&lt; &quot;,&quot; &lt;&lt; m_iY &lt;&lt; endl;
}

Coordinate::~Coordinate()
{
   cout &lt;&lt; &quot;~Coordinate()    &quot; &lt;&lt; m_iX &lt;&lt; &quot;,&quot; &lt;&lt; m_iY &lt;&lt; endl;
}

int Coordinate::getX()
{
   return m_iX;
}
</code></pre>
<p>2.Line.cpp定义</p>
<pre><code>#include&lt;iostream&gt;
#include&quot;Line.h&quot;
using namespace std;

class Line
{
public:
	Line(int x1, int y1, int x2, int y2);
	~Line();

	void printInfo();
private:
	Coordinate m_pCoorA;
	Coordinate m_pCoorB;
};

Line::Line(int x1, int y1, int x2, int y2) :m_pCoorA(Coordinate(x1, y1)),m_pCoorB(Coordinate(x2, y2)) //这里构造函数初始化务必使用初始化列表
{
	cout &lt;&lt; &quot;Line()&quot; &lt;&lt; endl;
};

Line::~Line()
{

	//delete m_pCoorA;
	//m_pCoorA = NULL;

	//delete m_pCoorB;
	//m_pCoorB = NULL;
	
	cout &lt;&lt; &quot;~Line()&quot; &lt;&lt; endl;
}

void Line::printInfo()
{
	cout &lt;&lt; &quot;printInfo&quot; &lt;&lt; endl;
	//cout &lt;&lt; &quot;(&quot; &lt;&lt; m_pCoorA-&gt;getX() &lt;&lt; &quot;,&quot; &lt;&lt; m_pCoorA-&gt;getY() &lt;&lt; &quot;)&quot; &lt;&lt; endl;
	//cout &lt;&lt; &quot;(&quot; &lt;&lt; m_pCoorB-&gt;getX() &lt;&lt; &quot;,&quot; &lt;&lt; m_pCoorB-&gt;getY() &lt;&lt; &quot;)&quot; &lt;&lt; endl;

	cout &lt;&lt; &quot;(&quot; &lt;&lt; m_pCoorA.getX() &lt;&lt; &quot;,&quot; &lt;&lt; m_pCoorA.getY() &lt;&lt; &quot;)&quot; &lt;&lt; endl;
	cout &lt;&lt; &quot;(&quot; &lt;&lt; m_pCoorB.getX() &lt;&lt; &quot;,&quot; &lt;&lt; m_pCoorB.getY() &lt;&lt; &quot;)&quot; &lt;&lt; endl;
}
</code></pre>
<p>3.demo.cpp定义</p>
<pre><code>#include&lt;iostream&gt;
#include&quot;Line.h&quot;
using namespace std;

int main()
{
	Line* p = new Line(1, 2, 3, 4);//利用对象指针实例化(从堆中开辟空间)
	delete p;
	p = NULL;
}
</code></pre>
<ul>
<li>对象指针：对象的指针成为了另外一个类的数据成员<br>
Line.cpp定义需要更改</li>
</ul>
<pre><code>#include&lt;iostream&gt;
#include&quot;Line.h&quot;
using namespace std;

class Line
{
public:
	Line(int x1, int y1, int x2, int y2);
	~Line();

	void printInfo();
private:
	Coordinate *m_pCoorA;
	Coordinate *m_pCoorB;
};

Line::Line(int x1, int y1, int x2, int y2)
{
	*m_pCoorA = Coordinate(x1, y1);
	*m_pCoorB = Coordinate(x2, y2);
	cout &lt;&lt; &quot;Line()&quot; &lt;&lt; endl;
};

Line::~Line()
{

	delete m_pCoorA;
	m_pCoorA = NULL;

	delete m_pCoorB;
	m_pCoorB = NULL;
	
	cout &lt;&lt; &quot;~Line()&quot; &lt;&lt; endl;
}

void Line::printInfo()
{
	cout &lt;&lt; &quot;printInfo&quot; &lt;&lt; endl;
	cout &lt;&lt; &quot;(&quot; &lt;&lt; m_pCoorA-&gt;getX() &lt;&lt; &quot;,&quot; &lt;&lt; m_pCoorA-&gt;getY() &lt;&lt; &quot;)&quot; &lt;&lt; endl;
	cout &lt;&lt; &quot;(&quot; &lt;&lt; m_pCoorB-&gt;getX() &lt;&lt; &quot;,&quot; &lt;&lt; m_pCoorB-&gt;getY() &lt;&lt; &quot;)&quot; &lt;&lt; endl;


}
</code></pre>
<h3 id="13总结">1.3总结</h3>
<p>作为对象成员和对象成员指针还有另外一个很大的不同。<br>
作为对象成员来说，如果我们使用sizeof这个对象的话，它就应该是里面所有对象的体积的总和。<br>
而对象成员指针则不同，我们来看一看刚刚对象成员指针我们定义的时候是如何定义的。我们可以看到，我们定义的时候呢，是写了两个指针作为它的对象成员。而我们知道，一个指针在32位的编译器下面，它只占4个基本内存单元，那么两个指针呢，则占8个基本内存单元，而我们前面所讲到的Coordinate类呢，它有两个数据成员，这两个数据成员都是int型的，所以呢，每一个数据成员都应该占4个基本的内存单元。那么这样算下来呢，我们来想一想，如果我们使用sizeof来判断一个line这样的对象，到底有多大呢？如果在line这个对象中定义的是对象成员（即两个Coordinate），那么这两个Coordinate每一个就应该都占8个基本内存单元，那么两个呢，就应该占16个基本内存单元，打印出来就应该是<strong>16</strong>，但是现在呢，line对象中是两个对象成员指针，那么每一个对象成员指针应该只占4个基本内存单元，所以sizeof(line)计算出来就应该是<strong>8</strong>，加起来是这两个指针的大小的总和。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[【转载】[1]算法工程师学习路线]]></title>
        <id>https://currydai.com/post/zhuan-zai-suan-fa-gong-cheng-shi-xue-xi-lu-xian/</id>
        <link href="https://currydai.com/post/zhuan-zai-suan-fa-gong-cheng-shi-xue-xi-lu-xian/">
        </link>
        <updated>2021-02-11T07:05:14.000Z</updated>
        <content type="html"><![CDATA[<h2 id="一-学习路线">一、学习路线</h2>
<p>主要分为 4 个部分：<strong>数学基础、编程能力、算法基础、实战</strong>。<br>
https://github.com/Jack-Cherish/awesome-cs-books</p>
<h3 id="1-数学基础">1、数学基础</h3>
<p>在机器学习算法中，涉及到最为重要的数学基本知识有两个：线性代数和概率论。</p>
<p><strong>线性代数</strong>作为研究空间的一门科学，是入门机器学习的最要基础之一。<br>
视频：推荐 MIT 的老教授 Gilbert Strang 的线性代数上课视频。<br>
教材：推荐《线性代数及其应用》，作者是 David C. Lay 。PS：资源下载见文末。这本书详细地介绍了线性代数在几何学、计算机图形学、经济学、概率论、信号与系统、微分方程等领域的应用，给人以直观的认识。<br>
<strong>概率论</strong>是研究不确定性的一门科学，生活处处是概率。机器学习算法需要对现实情况建模，自然是少不了将概率论作为工具。这里推荐陈希儒的《概率论与数理统计》，讲得很详细，如同听一个老者回忆自己的概率与统计心得，相信读者也会有所收获。</p>
<h3 id="2-编程能力">2、编程能力</h3>
<p>编程语言，需要至少掌握两门， Python 和 C++。</p>
<ul>
<li>
<p><strong>Python</strong>主要用于处理数据、算法调研、模型训练的工作，而 C++ 则是负责工程落地。<br>
算法工程师，需要针对落地场景，对算法的可靠性和实时性等方面进行优化，C++ 工程能力必不可少。</p>
<p>视频：我上学看的第一个视频，就是小甲鱼 Python 课程，风趣幽默，涉及Python 语法基础、网络爬虫、Pygame 飞机大战等内容，内容很丰富。</p>
<p>实战是最好的老师，学习 Python 的时候，可以找一个自己喜欢的方向，去实战。边实战，边学习。比如写爬虫、做小游戏、玩各种有趣的算法等。这里面，爬虫是最简单的，很容易有成就感，让你坚持学习下去，下载小说、下载漫画、下载音乐、下载电影、抢票等等小程序。<br>
这个推荐我的一个 Github star 量 11.4k+、fork 4.5k+的爬虫项目。<br>
每个实战，都有对应的文章教程，代码开源。<br>
项目地址：https://github.com/Jack-Cherish/python-spider</p>
<p>教材：推荐《流畅的Python》，书看完有些难度，但是哪来当个手册用，很方便，哪些语法忘记了，翻阅一番，必能有所收获。</p>
</li>
<li>
<p>**C++**是一种面向对象的程序设计语言，无论你是做算法，还是做开发，亦或者是做测开。C++ 都应该掌握，它是一个基础的编程语言。学会了这门编程语言，再学其它，就会更得心应手。</p>
<p>视频：这部分推荐慕课网的免费教程，很好的入门视频，老师讲得绘声绘色、形象生动、通熟易懂。<br>
一共分为 7 章，每章视频的时间是 2-3 个小时，半个月可以轻松刷完，学习顺序是：<br>
C++远征之起航篇<br>
C++远征之离港篇<br>
C++远征之封装篇（上）<br>
C++远征之封装篇（下）<br>
C++远征之继承篇<br>
C++远征之多态篇<br>
C++远征之模板篇</p>
<p>教材：推荐被誉为“圣经”的《C++ Primer》，经典巨著，非常棒的书。PS：资源下载见文末。<br>
编程语言基础学完了，接下来就是数据结构与算法。</p>
</li>
<li>
<p><strong>数据结构与算法</strong>是程序员的内功，每一个工程师的必修课。数据结构的学法，我推荐是直接看书，一边学习一边刷题，同时进行，这样学的速度快。<br>
《图解算法》就如同书名一样，这是一本像小说一样有趣的算法入门书，非常易懂，强烈推荐。<br>
《剑指Offer》，里面讲解了 66 道+ 常见数据结构题，解析思路，简单易懂。<br>
两门书一起看，轻松入门数据结构与算法。<br>
不过《剑指Offer》讲解的代码都是 C/C++，没有 Python 版本，想看 Python 版本的，可以看我整理的教程，C++ 和 Python 都有实现和讲解，题目已按照类型划分好。<br>
项目地址：https://github.com/Jack-Cherish/LeetCode<br>
两本书都看完，题也刷完了，那就算是入门了。<br>
《LeetCode》进阶<br>
力扣可以从 HOT 100 或 精选算法 200 题刷起，题目相对于《剑指Offer》要增加一些难度，但每道题目都有对应的解题思路和答案。坚持刷完 200 道，大多的面试轻松搞定，完全够用。当然要面试谷歌级别的大佬，Hard 题是不能放过的。<br>
刷题地址：https://leetcode-cn.com/<br>
Tip：刷一遍题，回头看还会忘，不要怀疑自己，要反复刷，反复练习。<br>
同时，推荐一份谷歌大佬的刷题笔记：<br>
Jack-Cui：看完谷歌师兄的刷题笔记，多语言通吃，秒杀 88% Leetcode 题目</p>
</li>
</ul>
<h3 id="3-算法基础">3、算法基础</h3>
<p>恭喜大家，在做了前面这么多基础工作之后，终于可以开始入门机器学习算法了。</p>
<p><strong>机器学习：</strong><br>
视频：推荐吴恩达老师的机器学习视频，吴恩达是整个领域的巨头之一，学术地位很高。同时，他出的视频也对新手非常友好，入门的不二之选。<br>
教材：还是那句话，光看不练是不行的。《机器学习实战》，理论结合实战，适合新手。<br>
《机器学习实战》使用 Python2 实现，有些细节讲的不够细致，对此我进行了完善，使用 Python3 复现了一遍，并结合 sklearn 以及更多的好玩例子，进行讲解。<br>
全网阅读量 500w+：<br>
对应的 Github 开源代码 Star 3.3k+，fork 3.1k+。<br>
在线阅读地址：<br>
https://cuijiahua.com/blog/ml/</p>
<p><strong>深度学习：</strong><br>
深度学习是现在的算法工程师绕不开的一个子领域，是机器学习的子集。<br>
视频：还是推荐吴恩达老师的深度学习视频，也是对新手非常友好。<br>
教材：说实话，深度学习，我并没有看过书，都是视频+ Github 开源项目学习的，不过被誉为深度学习领域圣经的“花书”，可以备一本。PS：资源下载见文末。<br>
深度学习框架：<br>
深度学习框架有很多，Tensorflow、Pytorch、Paddle、MXNet、Caffe等。<br>
我在工作过程中，用的最多的是 Pytorch，其次是 Tensorflow。<br>
新手上手，推荐先学 Pytorch，可以直接看 Yunjey Choi 大佬的 Github 教程，简单入门：<br>
项目地址：<br>
https://github.com/yunjey/pytorch-tutorial<br>
Pytorch 深度学习框架学习，也可以看我写的 Pytorch 深度学习实战系列教程，有垃圾分类、图像分割等结合实战的小项目。<br>
Github 开源代码 Star 400+，fork 250+。<br>
项目地址：<br>
https://github.com/Jack-Cherish/Deep-Learning</p>
<h3 id="4-实战">4、实战</h3>
<p>实战实战，文章反复提到了这么多次，仅仅这些还是远远不够的。<br>
因为更多时候，你是跟着视频 or 文章的思路去实战，这缺少了独立思考的过程。<br>
学了这么多，你并没有独立完成过一个项目，数据怎么处理，怎么分析问题，用什么算法解决问题，也没有独立思考过。<br>
算法工程师的岗位竞争也比较激烈的，为了在茫茫人海中脱颖而出，我们需要以团队或个人的形式，独立完成一些项目，只有这样，你才能更具竞争力。<br>
对于学生党，做项目，最简单直接的方法就是参加竞赛。<br>
推荐两个参加竞赛的地方，一个是国外的 Kaggle，另一个是国内的阿里云天池。<br>
两个竞赛的奖金也都很丰富，根据自己的喜好，参赛即可。<br>
Kaggle：https://www.kaggle.com/<br>
阿里天池：https://tianchi.aliyun.com/competition/gameList/activeList<br>
既能打比赛，又能赢奖金，何乐而不为呢？</p>
<h2 id="三-资料打包">三、资料打包</h2>
<p>本文提到的资料，我都整理好了有需要的自取（提取码：jack）：<br>
链接：https://pan.baidu.com/s/12tbVrUF056pY7aCyMpgl1w</p>
<h2 id="四-总结">四、总结</h2>
<p>这篇文章整理的也是我的学习路线。<br>
要说需要学多久，那就看个人的学习动力了。<br>
如果你想去一家不错的公司，但是目前硬实力不过关，我觉得还是有必要去努力一下的，技术能力的高低决定你能走多远，平台的高低，决定你能飞多高。<br>
如果可以通过自己的努力，进入自己心仪的公司，一定不要松懈怠慢，职场成长和学习新技术一样，不进则退<br>
你往往会发现，身边实力越强的人越努力，最高级的自律就是享受孤独。<br>
刷题的话，也可以看另外一个大佬的刷题笔记。<br>
Jack-Cui：看完谷歌师兄的刷题笔记，多语言通吃，秒杀 88% Leetcode 题目<br>
<img src="https://currydai.com/post-images/1613828474102.png" alt="" loading="lazy"></p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[【图像处理】[2]opencv教程]]></title>
        <id>https://currydai.com/post/tu-xiang-chu-li-opencv-jiao-cheng/</id>
        <link href="https://currydai.com/post/tu-xiang-chu-li-opencv-jiao-cheng/">
        </link>
        <updated>2021-02-10T15:15:34.000Z</updated>
        <content type="html"><![CDATA[<p>@</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[【机器学习】[4]专题：深度学习框架介绍（RNNvsCNNvsDNN）]]></title>
        <id>https://currydai.com/post/ji-qi-xue-xi-4zhuan-ti-rnn-cnn-dnn-lstm-shi-shi-me/</id>
        <link href="https://currydai.com/post/ji-qi-xue-xi-4zhuan-ti-rnn-cnn-dnn-lstm-shi-shi-me/">
        </link>
        <updated>2021-02-10T08:32:34.000Z</updated>
        <content type="html"><![CDATA[<h2 id="0序言">0.序言</h2>
<p>第一代神经网络又称为感知器，在1950年左右被提出来，它的算法只有两层，输入层输出层，主要是线性结构。它不能解决线性不可分的问题，对稍微复杂一些的函数都无能为力，如异或操作。<br>
为了解决第一代神经网络的缺陷，在1980年左右Rumelhart、Williams等人提出第二代神经网络多层感知器（MLP）。和第一代神经网络相比，第二代在输入层之间有多个隐含层的感知机，可以引入一些非线性的结构，解决了之前无法模拟异或逻辑的缺陷。<br>
第二代神经网络让科学家们发现神经网络的层数直接决定了它对现实的表达能力，但是随着层数的增加，优化函数愈发容易出现局部最优解的现象，由于存在梯度消失的问题，深层网络往往难以训练，效果还不如浅层网络。<br>
2006年Hinton采取无监督预训练（Pre-Training）的方法解决了梯度消失的问题，使得深度神经网络变得可训练，将隐含层发展到7层，神经网络真正意义上有了“深度”，由此揭开了深度学习的浪潮，第三代神经网络开始正式兴起。</p>
<h2 id="1dnn深层神经网络">1.DNN：深层神经网络</h2>
<p>从结构上来说，DNN和传统意义上的NN（神经网络）并无太大区别，最大的不同是层数增多了，并解决了模型可训练的问题。简言之，DNN比NN多了一些隐层，但这些隐层的作用是巨大的，带来的效果是非常显著和神奇的。<br>
当然第三代神经网络能够带来神奇的效果，并不仅仅是因为它的模型结构和训练方法更为优化、算法更加先进，最重要的是随着移动互联网的普及海量数据的产生和机器计算能力的增强。<br>
DNN中的“deep”意为深度，但深度学习中深度没有固定的定义或者衡量标准，不同问题的解决所需要的隐含层数自然也是不相同的，就大家比较熟识的语音识别来说，解决问题可能4层就够了，但一般图像识别需要达到20多层才能够解决问题。<br>
DNN最大的问题是只能看到预先设定的长度的数据，对于语音和语言等前后相关的时序信号的表达能力还是有限的，基于此提出了RNN模型，即递归神经网络。<br>
缺陷：其一是全连接需要构建海量的元素节点，一次完整的训练可能需要生成千万级的权重参数，对于有限计算资源，瓶颈十分明显；其二是全连接层的计算原理使图像失去了其原有的空间属性，对于颠倒，平移或其他信号处理十分敏感，识别效果有限。<br>
CNN最主要的工作特点有两个：第一点，他是局部的，第二点，他是共产主义的。</p>
<h2 id="2rnn递归神经网络循环神经网络recurrent-neural-network">2.RNN：递归神经网络/循环神经网络（recurrent neural network）</h2>
<p>全连接的DNN存在着一个无法解决的问题：无法对时间序列上的变化进行建模。<br>
为了应对这种需求，业内提出了上文中提到的递归神经网络RNN。<br>
在普通的全连接网络中，DNN的隐层只能够接受到当前时刻上一层的输入，而在RNN中，神经元的输出可以在下一时间段直接作用到本身。换句话说，就是递归神经网络它的隐层不但可以接收到上一层的输入，也可以得到上一时刻当前隐层的输入。<br>
这一个变化的重要意义就在于使得神经网络具备了历史记忆的功能，原则上它可以看到无穷长的历史信息，这非常适合于像语音语言这种具有长时相关性的任务</p>
<h2 id="3cnn卷积神经网络convolution-network">3.CNN：卷积神经网络（convolution network）</h2>
<p>CNN真正能做的，只是起到一个特征提取器的作用</p>
<h3 id="31什么是卷积神经网络">3.1什么是卷积神经网络</h3>
<p>卷积神经网络主要是模拟人的视觉神经系统提出来的。<br>
卷积神经网络的结构依旧包括输入层、隐藏层和输出层，其中卷积神经网络的隐含层包含卷积层、池化层和全联接层3类常见构筑，接下来我们着重讲解下卷积和池化的相关知识点。<br>
<strong>卷积层</strong>的功能是对输入数据进行特征提取，其内部包含多个卷积核，一个卷积核覆盖的原始图像的范围叫做感受野（权值共享）。一次卷积运算(哪怕是多个卷积核)提取的特征往往是局部的，难以提取出比较全局的特征，因此需要在一层卷积基础上继续做卷积计算，这就是多层卷积。<br>
在卷积层进行特征提取后，输出的特征图会被传递至<strong>池化层</strong>进行特征选择和信息过滤。池化层包含预设定的池化函数，其功能是将特征图中单个点的结果替换为其相邻区域的特征图统计量。通过这种池化的操作，能够一定程度上克服图像的一些旋转和局部的细微变化，从而使得特征的表达更加稳定。<br>
权值共享：对于同一个卷积核，其会滑动过图像的所有位置，也就是所谓的共享权重，即在某一次卷积计算中，图像所有局部区域的一个卷积乘子是相同的，使用多个不同的卷积核来提取不通的特征。</p>
<h3 id="32走入cnn">3.2走入CNN</h3>
<ul>
<li>
<p>卷积神经网络：是一种专门用来处理具有类似网格结构的数据的神经网络</p>
</li>
<li>
<p>卷积：输入*核函数=特征映射<br>
<img src="https://currydai.com/post-images/1612966998016.png" alt="" loading="lazy"><br>
张量：高维数组统称<br>
卷积运算通过三个重要的思想来帮助改进机器学习系统：稀疏交互 (sparseinteractions)、参数共享 (parameter sharing)、等变表示 (equivariant representations)。</p>
</li>
<li>
<p>池化层：池化函数使用某一位置的相邻输出的总体统计特征来代替网络在该位置的输出。<br>
常用的有：最大池化、相邻矩形区域的平均值、L2范数、中心像素距离的加权平均函数</p>
</li>
<li>
<p>朴素的CNN一般采取卷积池化-&gt;卷积池化-&gt;……-&gt;卷积池化-&gt;全连接-&gt;全连接的方式进行架构。<br>
较为复杂的CNN结构则可能采取切块并行，深层卷积，残差结构等，如VGGnet使用了16，19层的网络，Resnet使用了跨层的卷积方法等</p>
</li>
</ul>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[【机器学习】tensorflow && Keras从入门到精通]]></title>
        <id>https://currydai.com/post/ji-qi-xue-xi-tensorflow-jiao-cheng/</id>
        <link href="https://currydai.com/post/ji-qi-xue-xi-tensorflow-jiao-cheng/">
        </link>
        <updated>2021-02-10T05:55:11.000Z</updated>
        <content type="html"><![CDATA[<p>@</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[【机器学习】Pytorch中文教程]]></title>
        <id>https://currydai.com/post/ji-qi-xue-xi-pytorch-zhong-wen-jiao-cheng/</id>
        <link href="https://currydai.com/post/ji-qi-xue-xi-pytorch-zhong-wen-jiao-cheng/">
        </link>
        <updated>2021-02-10T05:39:53.000Z</updated>
        <content type="html"><![CDATA[<h2 id="学习内容">学习内容</h2>
<p>主要学习笔记都在Jupyter中，包括基础以及教程实践</p>
<h2 id="代码托管">代码托管</h2>
<p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>h</mi><mi>t</mi><mi>t</mi><mi>p</mi><mi>s</mi><mo>:</mo><mi mathvariant="normal">/</mi><mi mathvariant="normal">/</mi><mi>g</mi><mi>i</mi><mi>t</mi><mi>h</mi><mi>u</mi><mi>b</mi><mi mathvariant="normal">.</mi><mi>c</mi><mi>o</mi><mi>m</mi><mi mathvariant="normal">/</mi><mi>c</mi><mi>u</mi><mi>r</mi><mi>r</mi><mi>y</mi><mi>d</mi><mi>a</mi><mi>i</mi><mi mathvariant="normal">/</mi><mi>P</mi><mi>y</mi><mi>t</mi><mi>o</mi><mi>r</mi><mi>c</mi><mi>h</mi><mo>−</mo><mi>J</mi><mi>u</mi><mi>p</mi><mi>y</mi><mi>t</mi><mi>e</mi><mi>r</mi><mo>−</mo><mi>S</mi><mi>t</mi><mi>u</mi><mi>d</mi><mi>y</mi><mi mathvariant="normal">.</mi><mi>g</mi><mi>i</mi><mi>t</mi></mrow><annotation encoding="application/x-tex">https://github.com/currydai/Pytorch-Jupyter-Study.git
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathdefault">h</span><span class="mord mathdefault">t</span><span class="mord mathdefault">t</span><span class="mord mathdefault">p</span><span class="mord mathdefault">s</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">:</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">/</span><span class="mord">/</span><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="mord mathdefault">i</span><span class="mord mathdefault">t</span><span class="mord mathdefault">h</span><span class="mord mathdefault">u</span><span class="mord mathdefault">b</span><span class="mord">.</span><span class="mord mathdefault">c</span><span class="mord mathdefault">o</span><span class="mord mathdefault">m</span><span class="mord">/</span><span class="mord mathdefault">c</span><span class="mord mathdefault">u</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="mord mathdefault">d</span><span class="mord mathdefault">a</span><span class="mord mathdefault">i</span><span class="mord">/</span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="mord mathdefault">t</span><span class="mord mathdefault">o</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mord mathdefault">c</span><span class="mord mathdefault">h</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.8777699999999999em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.09618em;">J</span><span class="mord mathdefault">u</span><span class="mord mathdefault">p</span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="mord mathdefault">t</span><span class="mord mathdefault">e</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.05764em;">S</span><span class="mord mathdefault">t</span><span class="mord mathdefault">u</span><span class="mord mathdefault">d</span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="mord">.</span><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="mord mathdefault">i</span><span class="mord mathdefault">t</span></span></span></span></span></p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[【ML实践】合成大西瓜：机器学习vs人工大脑]]></title>
        <id>https://currydai.com/post/ji-qi-xue-xi-shi-jian-1li-yong-ji-qi-xue-xi-he-cheng-da-xi-gua/</id>
        <link href="https://currydai.com/post/ji-qi-xue-xi-shi-jian-1li-yong-ji-qi-xue-xi-he-cheng-da-xi-gua/">
        </link>
        <updated>2021-02-09T15:44:05.000Z</updated>
        <content type="html"><![CDATA[<p>@</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[【ML实践】如何一步步提升识别手写数字的精度？]]></title>
        <id>https://currydai.com/post/ji-qi-xue-xi-3zhuan-ti-tu-xiang-chu-li/</id>
        <link href="https://currydai.com/post/ji-qi-xue-xi-3zhuan-ti-tu-xiang-chu-li/">
        </link>
        <updated>2021-02-03T02:00:09.000Z</updated>
        <content type="html"><![CDATA[<h2 id="1项目介绍">1.项目介绍</h2>
<p>数字识别的概念是光学字符识别（OCR）的子概念，而光学字符识别起源于电报技术和为盲人创建阅读设备的技术。研究初期，识别的文字对象仅为0-9的数字，直至1965至1970年之间开始有一些简单的产品，数字识别技术开始被应用在邮编识别等工作场景中。1985年，Shildhar和Badreldin提出了能够准确识别手写数字的算法，他们使用拓扑特征，并结合语法分类器以高精度识别手写数字。1989年，Yann LeCun等人在贝尔实验室将使用反向传播算法训练的卷积神经网络结合到读取“手写”数字上，并成功应用于识别美国邮政服务提供的手写邮政编码数字，成为了LeNet系列卷积网络的雏形。同年，Yann LeCun在发表的另一篇论文中描述了一个小的手写数字识别问题，并且表明即使该问题是线性可分的，单层网络也表现出较差的泛化能力。而当在多层的、有约束的网络上使用有位移不变性的特征检测器（shift invariant feature detectors）时，该模型可以在此任务上表现得非常好。1990年他们发表的论文再次描述了反向传播网络在手写数字识别中的应用，他们仅对数据进行了最小限度的预处理，而模型则是针对这项任务精心设计的，并且对其进行了高度约束。输入数据由图像组成，每张图像上包含一个数字，在美国邮政服务提供的邮政编码数字数据上的测试结果显示该模型的错误率仅有1%，拒绝率约为9%。<br>
1994年，Yann LeCun，Leon Bottou等人比较了几个分类算法在手写数字标准数据库上的性能，该比较同时考虑了准确率、训练时间、识别时间等。1998年，Yann LeCun，Leon Bottou，Yoshua Bengio和Patrick Haffner等人再次发表论文，回顾了应用于手写字符识别的各种方法，并用标准手写数字识别基准任务对这些模型进行了比较，结果显示卷积神经网络的表现超过了其他所有模型。该研究获得了巨大的成功，从那时起，神经网络及他们使用的MNIST数据集成为了手写数字识别的流行算法和验证算法的基本数据集。<br>
当然，神经网络并不是识别手写数字的唯一算法。早于1997年，Scholkopf等人就使用支持向量机在（SVＭ）美国手写数字邮政服务数据库上进行了测试，测试的模型有使用RBF内核的SVM、高斯核函数的SVM和由SVＭ方法确定的中心和由误差反向传播训练的权重的混合系统，结果显示支持向量机在当时的模型中实现了最高的精度。<br>
（手写）数字识别目前已成为人工智能领域及计算机视觉领域的基本问题，大量的识别算法涌现，近几年来在MNIST数据集上，其识别准确率更是高达99%。<br>
MNIST手写数字数据集来源于是美国国家标准与技术研究所，是著名的公开数据集之一，通常这个数据集都会被作为深度学习的入门案例。数据集中的数字图片是由250个不同职业的人纯手写绘制，数据集获取的网址为：http://yann.lecun.com/exdb/mnist/。<br>
具体来看，MNIST手写数字数据集包含有60000张图片作为训练集数据，10000张图片作为测试集数据，且每一个训练元素都是28*28像素的手写数字图片，每一张图片代表的是从0到9中的每个数字。<br>
<img src="https://currydai.com/post-images/1612880529161.png" alt="" loading="lazy"></p>
<h2 id="2数据预处理">2.数据预处理</h2>
<p>如果我们把每一张图片中的像素转换为向量，则得到长度为28*28=784的向量。因此我们可以把MNIST数据训练集看作是一个[60000,784]的张量，第一个维度表示图片的索引，第二个维度表示每张图片中的像素点。而图片里的每个像素点的值介于0-255之间。<br>
此外，MNIST数据集的类标是介于0-9的数字，共10个类别。通常我们要用独热编码（One_Hot Encoding）的形式表示这些类标。所谓的独热编码，直观的讲就是用N个维度来对N个类别进行编码，并且对于每个类别，只有一个维度有效，记作数字1 ；其它维度均记作数字0。例如类标1表示为：([0,1,0,0,0,0,0,0,0,0])；同理标签2表示为：([0,0,1,0,0,0,0,0,0,0])。最后我们通过softmax函数输出的是每张图片属于10个类别的概率。<br>
原始数据数据以非常简单的文件格式存储，旨在存储矢量和多维矩阵。因此在使用前需要转换，其具体转换过程参考了网友的结果，再次表示感谢。<br>
<img src="https://currydai.com/post-images/1612881662101.png" alt="" loading="lazy"></p>
<pre><code>import numpy as np
import struct
from matplotlib import pyplot as plt
import pandas as pd

 ##解析idx3文件的通用函数
def decode_idx3_ubyte(idx3_ubyte_file):
    #读取二进制文件
    bin_data = open(idx3_ubyte_file, 'rb').read()
    
    #解析文件信息
    offset = 0
    fmt_header = '&gt;iiii'
    magic_number, num_images, num_rows, num_cols = struct.unpack_from(fmt_header, bin_data, offset)
    #print('魔数:%d, 图片数量: %d张, 图片大小: %d*%d' % (magic_number, num_images, num_rows, num_cols))

    #解析数据集
    image_size = num_rows * num_cols
    offset += struct.calcsize(fmt_header)
    #print(offset)
    fmt_image = '&gt;' + str(image_size) + 'B'
    #print(fmt_image,offset,struct.calcsize(fmt_image))
    images = np.empty((num_images, num_rows*num_cols,1))

    for i in range(num_images):
        #if (i + 1) % 10000 == 0:
            #print('已解析 %d' % (i + 1) + '张')
            #print(offset)
        images[i] = np.array(struct.unpack_from(fmt_image, bin_data, offset)).reshape((num_cols*num_rows,1))
        offset += struct.calcsize(fmt_image)

    return images

def decode_idx1_ubyte(idx1_ubyte_file):
    &quot;&quot;&quot;
    解析idx1文件的通用函数
    :param idx1_ubyte_file: idx1文件路径
    :return: 数据集
    &quot;&quot;&quot;
    # 读取二进制数据
    bin_data = open(idx1_ubyte_file, 'rb').read()

    # 解析文件头信息，依次为魔数和标签数
    offset = 0
    fmt_header = '&gt;ii'
    magic_number, num_images = struct.unpack_from(fmt_header, bin_data, offset)
    #print('魔数:%d, 图片数量: %d张' % (magic_number, num_images))

    # 解析数据集
    offset += struct.calcsize(fmt_header)
    fmt_image = '&gt;B'
    labels = np.empty(num_images)
    for i in range(num_images):
        #if (i + 1) % 10000 == 0:
            #print ('已解析 %d' % (i + 1) + '张')
        labels[i] = struct.unpack_from(fmt_image, bin_data, offset)[0]
        offset += struct.calcsize(fmt_image)

        
    return labels

def load_train_images(train_images_idx3_ubyte_file):
    idx_ubyte_file=train_images_idx3_ubyte_file
    return decode_idx3_ubyte(idx_ubyte_file)

def load_train_labels(train_labels_idx1_ubyte_file):
    idx_ubyte_file=train_labels_idx1_ubyte_file
    return decode_idx1_ubyte(idx_ubyte_file)

def load_test_images(test_images_idx3_ubyte_file):
    idx_ubyte_file=test_images_idx3_ubyte_file
    return decode_idx3_ubyte(idx_ubyte_file)

def load_test_labels(test_labels_idx1_ubyte_file):
    idx_ubyte_file=test_labels_idx1_ubyte_file
    return decode_idx1_ubyte(idx_ubyte_file)

if __name__=='__main__':
    
    def vectorized_result(j):
        e = np.zeros((10, 1))
        e[int(j)] = 1.0
        return e

    train_images_idx3_ubyte_file = 'D:/git_lab/game/minst/MNIST_Play/1_MNIST/1_MNIST/train-images-idx3-ubyte'
    train_labels_idx1_ubyte_file = 'D:/git_lab/game/minst/MNIST_Play/1_MNIST/1_MNIST/train-labels-idx1-ubyte'
    test_images_idx3_ubyte_file = 'D:/git_lab/game/minst/MNIST_Play/1_MNIST/1_MNIST/t10k-images-idx3-ubyte'
    test_labels_idx1_ubyte_file = 'D:/git_lab/game/minst/MNIST_Play/1_MNIST/1_MNIST/t10k-labels-idx1-ubyte'
    
    
    
    train_images = pp.load_train_images(train_images_idx3_ubyte_file)
    train_labels = [vectorized_result(i) for i in pp.load_train_labels(train_labels_idx1_ubyte_file)]
    
    test_images = pp.load_test_images(test_images_idx3_ubyte_file)
    test_labels = pp.load_test_labels(test_labels_idx1_ubyte_file)
    
    
    
    training_data=list(zip(train_images,train_labels))
    test_data=list(zip(test_images,test_labels))
</code></pre>
<h2 id="3网络架构">3.网络架构</h2>
<h3 id="31-手动实现bp神经网络">3.1 手动实现BP神经网络</h3>
<p>参照《神经网络与深度学习》一书，利用BP神经网络的基本性质结合python实现了网络框架，具体就是设置三层网络，包括784的输入，30-n的隐藏层以及10个输出层，利用梯度下降以及反向传播算法实现参数自动更新。<br>
<img src="https://currydai.com/post-images/1612882031758.png" alt="" loading="lazy"></p>
<pre><code>import numpy as np
import random
import struct
import process_pic as pp
import matplotlib.pyplot as plt

class Network():
    
    def __init__(self,sizes):
        self.num_layers=len(sizes)
        self.sizes=sizes
        self.biases=[np.random.randn(y,1) for y in sizes[1:]]
        self.weights=[np.random.randn(y,x) for x, y in zip(sizes[:-1], sizes[1:])]
        
    def feedforward(self,a):
        for b,w in zip(self.biases,self.weights):
            a=self.sigmoid(np.dot(w,a)+b)
        return a
        
    def SGD(self,training_data,epochs,mini_batch_size,eta,test_data):
        if(test_data):
            n_test=len(test_data)
        n=len(training_data)
        plt.ion()
        for j in range(epochs):
            random.shuffle(training_data)
            mini_batchs=[training_data[k:k+mini_batch_size]  for k in range(0,n,mini_batch_size)]
            for mini_batch in mini_batchs:
                self.update_mini_batch(mini_batch,eta)
            if test_data:
                print('Epoch %s:%s/%s'%(j,self.evaluate(test_data),n_test))
                #plt.grid(linestyle='-.')
                plt.title(&quot;accuracy=%s&quot;%(self.evaluate(test_data)/n_test))
                plt.xlabel(&quot;epoch&quot;)
                plt.ylabel(&quot;accuracy&quot;)
                plt.xlim(0,epochs)
                plt.ylim(0,1) 
                plt.scatter(j, self.evaluate(test_data)/n_test)
                plt.pause(0.5)
            else:
                print('Epoch %s complete'%j)
        plt.ioff()
        plt.show()
                
    def update_mini_batch(self,mini_batch,eta):
        nabla_b = [np.zeros(b.shape) for b in self.biases]
        nabla_w = [np.zeros(w.shape) for w in self.weights]
        for x, y in mini_batch:
            delta_nabla_b, delta_nabla_w = self.backprop(x, y)
            nabla_b = [nb+dnb for nb, dnb in zip(nabla_b, delta_nabla_b)]
            nabla_w = [nw+dnw for nw, dnw in zip(nabla_w, delta_nabla_w)]
        self.weights = [w-(eta/len(mini_batch))*nw for w, nw in zip(self.weights, nabla_w)]
        self.biases = [b-(eta/len(mini_batch))*nb for b, nb in zip(self.biases, nabla_b)]
    
    def backprop(self, x, y):
       nabla_b = [np.zeros(b.shape) for b in self.biases]
       nabla_w = [np.zeros(w.shape) for w in self.weights]
       activation = x
       activations = [x] 
       zs = []
       for b, w in zip(self.biases, self.weights):
           z = np.dot(w, activation)+b
           zs.append(z)
           activation = self.sigmoid(z)
           activations.append(activation)
       delta = self.cost_derivative(activations[-1], y) * self.sigmoid_prime(zs[-1])
       nabla_b[-1] = delta
       nabla_w[-1] = np.dot(delta, activations[-2].transpose())
       for l in range(2, self.num_layers):
           z = zs[-l]
           sp = self.sigmoid_prime(z)
           delta = np.dot(self.weights[-l+1].transpose(), delta) * sp
           nabla_b[-l] = delta
           nabla_w[-l] = np.dot(delta, activations[-l-1].transpose())
       return (nabla_b, nabla_w)
   
    #返回神经网络为其输出正确结果的测试输入的数量。请注意，神经网络的输出被假定为最后一层中激活程度最高的任何神经元的索引
    def evaluate(self,test_data):
        test_results = [(np.argmax(self.feedforward(x)), y) for (x, y) in test_data]#最大值的索引
        #print(test_results)
        
        return sum(int(x == y) for (x, y) in test_results)
    
    def cost_derivative(self, output_activations, y):
        return (output_activations-y)
    
    def sigmoid(self,z):
        return 1.0/(1.0+np.exp(-z))
    
    def sigmoid_prime(self,z):
        return (self.sigmoid(z))*(1-self.sigmoid(z))
    
    
if __name__=='__main__':
    
    def vectorized_result(j):
        e = np.zeros((10, 1))
        e[int(j)] = 1.0
        return e

    train_images_idx3_ubyte_file = 'D:/git_lab/game/minst/MNIST_Play/1_MNIST/1_MNIST/train-images-idx3-ubyte'
    train_labels_idx1_ubyte_file = 'D:/git_lab/game/minst/MNIST_Play/1_MNIST/1_MNIST/train-labels-idx1-ubyte'
    test_images_idx3_ubyte_file = 'D:/git_lab/game/minst/MNIST_Play/1_MNIST/1_MNIST/t10k-images-idx3-ubyte'
    test_labels_idx1_ubyte_file = 'D:/git_lab/game/minst/MNIST_Play/1_MNIST/1_MNIST/t10k-labels-idx1-ubyte'
    
    
    
    train_images = pp.load_train_images(train_images_idx3_ubyte_file)
    train_labels = [vectorized_result(i) for i in pp.load_train_labels(train_labels_idx1_ubyte_file)]
    
    test_images = pp.load_test_images(test_images_idx3_ubyte_file)
    test_labels = pp.load_test_labels(test_labels_idx1_ubyte_file)
    
    
    
    training_data=list(zip(train_images,train_labels))
    test_data=list(zip(test_images,test_labels))
    
    
    net = Network([784, 16, 10])    
    net.SGD(training_data, 30, 1000, 1, test_data=test_data)
    #training_data,epochs,mini_batch_size,eta
</code></pre>
<figure data-type="image" tabindex="1"><img src="https://currydai.com/post-images/1612885074956.png" alt="" loading="lazy"></figure>
<h2 id="4提升精度">4.提升精度</h2>
<pre><code>

#### Libraries
# Standard library
import json
import random
import sys
import preprocess as pp
# Third-party libraries
import numpy as np


#### 定义二次代价函数与交叉熵函数

class QuadraticCost(object):
    

    @staticmethod
    def fn(a, y):
        return 0.5*np.linalg.norm(a-y)**2

    @staticmethod
    def delta(z, a, y):
        network2=Network([1,1,1],None)
        return (a-y) * network2.sigmoid_prime(z)


class CrossEntropyCost(object):

    @staticmethod
    def fn(a, y):
        return np.sum(np.nan_to_num(-y*np.log(a)-(1-y)*np.log(1-a)))

    @staticmethod
    def delta(z, a, y):
        return (a-y)


#### 定义BP神经网络架构
class Network(object):

    def __init__(self, sizes, cost=CrossEntropyCost):
        self.num_layers = len(sizes)
        self.sizes = sizes
        self.default_weight_initializer()
        self.cost=cost

    def default_weight_initializer(self):
        self.biases = [np.random.randn(y, 1) for y in self.sizes[1:]]
        self.weights = [np.random.randn(y, x)/np.sqrt(x) for x, y in zip(self.sizes[:-1], self.sizes[1:])]

    def large_weight_initializer(self):
        self.biases = [np.random.randn(y, 1) for y in self.sizes[1:]]
        self.weights = [np.random.randn(y, x)  for x, y in zip(self.sizes[:-1], self.sizes[1:])]

    def feedforward(self, a):
        for b, w in zip(self.biases, self.weights):
            a = self.sigmoid(np.dot(w, a)+b)
        return a

    def SGD(self, training_data, epochs, mini_batch_size, eta,
            lmbda = 0.0,
            evaluation_data=None,
            monitor_evaluation_cost=False,
            monitor_evaluation_accuracy=False,
            monitor_training_cost=False,
            monitor_training_accuracy=False):

        if evaluation_data: 
            n_data = len(evaluation_data)
        n = len(training_data)
        evaluation_cost, evaluation_accuracy = [], []
        training_cost, training_accuracy = [], []
        for j in range(epochs):
            random.shuffle(training_data)
            mini_batches = [training_data[k:k+mini_batch_size] for k in range(0, n, mini_batch_size)]
            for mini_batch in mini_batches:
                self.update_mini_batch(mini_batch, eta, lmbda, len(training_data))
            print (&quot;Epoch %s training complete&quot; % j)
            if monitor_training_cost:
                cost = self.total_cost(training_data, lmbda)
                training_cost.append(cost)
                print (&quot;Cost on training data: {}&quot;.format(cost))
            if monitor_training_accuracy:
                accuracy = self.accuracy(training_data, convert=True)
                training_accuracy.append(accuracy)
                print (&quot;Accuracy on training data: {} / {}&quot;.format(accuracy, n))
            if monitor_evaluation_cost:
                cost = self.total_cost(evaluation_data, lmbda, convert=True)
                evaluation_cost.append(cost)
                print (&quot;Cost on evaluation data: {}&quot;.format(cost))
            if monitor_evaluation_accuracy:
                accuracy = self.accuracy(evaluation_data)
                evaluation_accuracy.append(accuracy)
                print (&quot;Accuracy on evaluation data: {} / {}&quot;.format(self.accuracy(evaluation_data), n_data))
        return evaluation_cost, evaluation_accuracy,training_cost, training_accuracy

    def update_mini_batch(self, mini_batch, eta, lmbda, n):
        nabla_b = [np.zeros(b.shape) for b in self.biases]
        nabla_w = [np.zeros(w.shape) for w in self.weights]
        for x, y in mini_batch:
            delta_nabla_b, delta_nabla_w = self.backprop(x, y)
            nabla_b = [nb+dnb for nb, dnb in zip(nabla_b, delta_nabla_b)]
            nabla_w = [nw+dnw for nw, dnw in zip(nabla_w, delta_nabla_w)]
        self.weights = [(1-eta*(lmbda/n))*w-(eta/len(mini_batch))*nw for w, nw in zip(self.weights, nabla_w)]
        self.biases = [b-(eta/len(mini_batch))*nb for b, nb in zip(self.biases, nabla_b)]

    def backprop(self, x, y):
        nabla_b = [np.zeros(b.shape) for b in self.biases]
        nabla_w = [np.zeros(w.shape) for w in self.weights]
        # feedforward
        activation = x
        activations = [x] # list to store all the activations, layer by layer
        zs = [] # list to store all the z vectors, layer by layer
        for b, w in zip(self.biases, self.weights):
            z = np.dot(w, activation)+b
            zs.append(z)
            activation = self.sigmoid(z)
            activations.append(activation)
        # backward pass
        delta = (self.cost).delta(zs[-1], activations[-1], y)
        nabla_b[-1] = delta
        nabla_w[-1] = np.dot(delta, activations[-2].transpose())
        for l in range(2, self.num_layers):
            z = zs[-l]
            sp = self.sigmoid_prime(z)
            delta = np.dot(self.weights[-l+1].transpose(), delta) * sp
            nabla_b[-l] = delta
            nabla_w[-l] = np.dot(delta, activations[-l-1].transpose())
        return (nabla_b, nabla_w)

    def accuracy(self, data, convert=False):
        if convert:
            results = [(np.argmax(self.feedforward(x)), np.argmax(y))  for (x, y) in data]
        else:
            results = [(np.argmax(self.feedforward(x)), y) for (x, y) in data]
        return sum(int(x == y) for (x, y) in results)

    def total_cost(self, data, lmbda, convert=False):
        cost = 0.0
        for x, y in data:
            a = self.feedforward(x)
            if convert: 
                y = vectorized_result(y)
            cost += self.cost.fn(a, y)/len(data)
        cost += 0.5*(lmbda/len(data))*sum(np.linalg.norm(w)**2 for w in self.weights)
        return cost
    

    def sigmoid(self,z):
        return 1.0/(1.0+np.exp(-z))
    

    def sigmoid_prime(self,z):
        return self.sigmoid(z)*(1-self.sigmoid(z))
    
if __name__=='__main__':
    
    def vectorized_result(j):
        e = np.zeros((10, 1))
        e[int(j)] = 1.0
        return e
    
    train_images_idx3_ubyte_file = 'D:/git_lab/game/minst/MNIST_Play/1_MNIST/1_MNIST/train-images-idx3-ubyte'
    train_labels_idx1_ubyte_file = 'D:/git_lab/game/minst/MNIST_Play/1_MNIST/1_MNIST/train-labels-idx1-ubyte'
    test_images_idx3_ubyte_file = 'D:/git_lab/game/minst/MNIST_Play/1_MNIST/1_MNIST/t10k-images-idx3-ubyte'
    test_labels_idx1_ubyte_file = 'D:/git_lab/game/minst/MNIST_Play/1_MNIST/1_MNIST/t10k-labels-idx1-ubyte'
    
    
    
    train_images = pp.load_train_images(train_images_idx3_ubyte_file)
    train_labels = [vectorized_result(i) for i in pp.load_train_labels(train_labels_idx1_ubyte_file)]
    
    test_images = pp.load_test_images(test_images_idx3_ubyte_file)
    test_labels = pp.load_test_labels(test_labels_idx1_ubyte_file)
    
    
    
    training_data=list(zip(train_images,train_labels))
    test_data=list(zip(test_images,test_labels))
    
    net = Network([784, 30, 10], cost=CrossEntropyCost)
    net.default_weight_initializer()
    net.SGD(training_data, 30, 10, 0.5,  evaluation_data=test_data, lmbda = 0.1,monitor_evaluation_accuracy=True, monitor_training_cost=True)
</code></pre>
<figure data-type="image" tabindex="2"><img src="https://currydai.com/post-images/1612945862780.png" alt="" loading="lazy"></figure>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[【机器学习】[3]从手写字母认识神经网络]]></title>
        <id>https://currydai.com/post/ji-qi-xue-xi-3zhuan-ti-shen-jing-wang-luo-yu-shen-du-xue-xi/</id>
        <link href="https://currydai.com/post/ji-qi-xue-xi-3zhuan-ti-shen-jing-wang-luo-yu-shen-du-xue-xi/">
        </link>
        <updated>2021-02-03T01:56:30.000Z</updated>
        <content type="html"><![CDATA[<h2 id="1书籍阅读神经网络与深度学习">1.书籍阅读：《神经网络与深度学习》</h2>
<p>神经⽹络：⼀种美妙的受⽣物学启发的编程范式，可以让计算机从观测数据中进⾏学习<br>
深度学习：⼀个强有⼒的⽤于神经⽹络学习的众多技术的集合（2006~）<br>
在图像识别、语音识别以及自然语言处理领域最好的解决方案</p>
<h3 id="11-从手写识别字体认识神经网络">1.1 从手写识别字体认识神经网络</h3>
<p>⼿写识别常常被当成学习神经⽹络的原型问题<br>
MNIST数据集：60000幅训练图像以及10000幅测试数据  28*28灰度值</p>
<p>感知器：依据权重和阈值来做出决定的的单元<br>
S神经元：全新的人工神经元<br>
两者区别：后者在前者基础上加一个simgod函数，平滑化</p>
<p>前馈神经网络：上一层的输出作为下一层的输入，信息总是向前传播，从不反向回馈<br>
递归神经网络：单个神经元存在反馈回路</p>
<p>二次代价函数=均方误差=MSE<br>
训练的目的：找到能最小化二次代价函数的权重和偏置-&gt;微积分or暗推法<br>
梯度下降算法：重复计算梯度 ∇C，然后沿着相反的⽅向移动，沿着⼭⾕滚落<br>
这是⼀种⾮常有效的⽅式去求代价函数的最⼩值，进⽽促进⽹络⾃⾝的学习。<br>
随机梯度下降：随机选取⼩量训练输⼊样本来计算 ∇Cx，进⽽估算梯度 ∇C</p>
<p>从这得到的教训是调试⼀个神经⽹络不是琐碎的，就像常规编程那样，它是⼀⻔艺术。<br>
包含这种多层结构 —— 两层或更多隐藏层 —— 的⽹络被称为深度神经⽹络。<br>
神经⽹络如何使⽤梯度下降算法来学习他们⾃⾝的权重和偏置</p>
<ul>
<li><img src="file://C:/Users/10437/Documents/Gridea/post-images1612339857455.png" alt="" loading="lazy"></li>
<li><img src="https://currydai.com/post-images/1612340529447.png" alt="" loading="lazy"></li>
<li><img src="https://currydai.com/post-images/1612341065041.png" alt="" loading="lazy"></li>
<li><img src="https://currydai.com/post-images/1612341076729.png" alt="" loading="lazy"></li>
</ul>
<h2 id="12反向传播算法">1.2反向传播算法</h2>
<p>反向传播的核⼼是⼀个对代价函数 C 关于任何权重 w（或者偏置 b ）的偏导数 ∂C/∂w 的表达式。    这个表达式告诉我们在改变权重和偏置时，代价函数变化的快慢。尽管表达式会有点复杂，不过⾥⾯   也包含⼀种美感，就是每个元素其实是拥有⼀种⾃然的直觉上的解释。所以反向传播不仅仅是⼀种学习的快速算法。实际上它让我们细致领悟如何通过改变权重和偏置来改变整个⽹络的⾏为。因此，这也是学习反向传播细节的重要价值所在。<br>
<img src="https://currydai.com/post-images/1612923083695.png" alt="" loading="lazy"><br>
<img src="https://currydai.com/post-images/1612923091031.png" alt="" loading="lazy"><br>
<img src="https://currydai.com/post-images/1612923096546.png" alt="" loading="lazy"><br>
<img src="https://currydai.com/post-images/1612923101109.png" alt="" loading="lazy"></p>
<h3 id="121-反向传播两个假设">1.2.1 反向传播两个假设</h3>
<p><strong>第⼀个假设就是代价函数可以被写成⼀个在每个训练样本 x 上的代价函数 Cx的均值</strong><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>C</mi><mo>=</mo><mfrac><mn>1</mn><mi>n</mi></mfrac><msub><mo>∑</mo><mi>x</mi></msub><msub><mi>C</mi><mi>x</mi></msub></mrow><annotation encoding="application/x-tex">C=\frac{1}{n}\sum_xC_x</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.07153em;">C</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.190108em;vertical-align:-0.345em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.845108em;"><span style="top:-2.6550000000000002em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">n</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:-0.0000050000000000050004em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.0016819999999999613em;"><span style="top:-2.40029em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">x</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.29971000000000003em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.07153em;">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.07153em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">x</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>:需要这个假设的原因是反向传播实际上是对⼀个独⽴的训练样本计算了 ∂Cx/∂w 和 ∂Cx/∂b。然后我们通过在所有训练样本上进⾏平均化获得 ∂C/∂w 和 ∂C/∂b。<br>
<strong>第⼆个假设就是代价可以写成神经⽹络输出的函数:</strong></p>
<h3 id="122-反向传播四个基本方程">1.2.2 反向传播四个基本方程</h3>
<ul>
<li>输出层误差方程：增加很⼩的变化 ∆z在神经元的带权输⼊上，使得神经元输出由 σ(z) 变成 σ(z+ ∆z)。这个变化会向⽹络后⾯的层进⾏传播，最终导致整个代价产⽣(∂C/∂z)*∆z的改变</li>
<li>使用上一层的误差来表示当前层的误差</li>
<li>代价函数关于网络中任意偏置的改变率</li>
<li>代价函数关于任意一个权重的改变率<br>
<img src="https://currydai.com/post-images/1612922794375.png" alt="" loading="lazy">
<h3 id="123反向传播算法">1.2.3反向传播算法</h3>
<img src="https://currydai.com/post-images/1612923616222.png" alt="" loading="lazy"><br>
<img src="https://currydai.com/post-images/1612923752711.png" alt="" loading="lazy"></li>
</ul>
<h2 id="13提升神经网络精度">1.3提升神经网络精度</h2>
<h3 id="131交叉熵函数">1.3.1交叉熵函数</h3>
<p>二次代价函数vs交叉熵函数：在错误较大情况下，解决二次代价函数学习速度较缓问题<br>
<img src="https://currydai.com/post-images/1612926108594.png" alt="" loading="lazy"><br>
<img src="https://currydai.com/post-images/1612937198520.png" alt="" loading="lazy"><br>
初始误差越⼤，神经元学习得越快。这也能够解决学习速度下降的问题<br>
解决学习速度缓慢另外一个方法是柔性最大值神经元层(softmax)</p>
<h3 id="132-过度拟合和规范化">1.3.2 过度拟合和规范化</h3>
<p>我们的⽹络能够正确地对所有 1000 幅图像进⾏分类！⽽在同时，我们的测试准确率仅仅能够达到 82.27%。所以我们的⽹络实际上在学习训练数据集的特例，⽽不是能够⼀般地进⾏识别。我们的⽹络⼏乎是在单纯记忆训练集合，⽽没有对数字本质进⾏理解能够泛化到测试数据集上。防止过拟合的方法为：</p>
<ul>
<li>增加训练样本的数量：⼈为扩展训练数据</li>
<li>规范化技术：权重衰减（weight decay）或者 L2/L1 规范化</li>
<li>弃权技术： 弃权（Dropout）是⼀种相当激进的技术。和 L1、L2 规范化不同，弃权技术并不依赖对代价函数的修改。⽽是，在弃权中，我们改变了⽹络本⾝。<br>
--------扩展样本数量-----------------<br>
不只旋转，还转换和扭曲图像来扩展训练数据。通过在这个扩展后的数据集上的训练，他们提升到了 98.9% 的准确率。然后还在“弹性扭曲”的数据上进⾏了实验，这是⼀种特殊的为了模仿⼿部肌⾁的随机抖动的图像扭曲⽅法。通过使⽤弹性扭曲扩展的数据，他们最终达到了 99.3% 的分类准确率。他们通过展⽰训练数据的所有类型的变化形式来扩展⽹络的经验。<br>
--------其中L2规范化具体为：--------<br>
<img src="https://currydai.com/post-images/1612942583675.png" alt="" loading="lazy"><br>
规范化可以当做⼀种寻找⼩的权重和最⼩化原始的代价函数之间的折中。这两部分之间相对的重要性就由 λ 的值来控制了：λ 越⼩，就偏向于最⼩化原始代价函数，反之，倾向于⼩的权重。<br>
⼩的权重在某种程度上，意味着更低的复杂性，也就对数据给出了⼀种更简单却更强⼤解释，因此应该优先选择。</li>
</ul>
<h3 id="133-权重初始化">1.3.3 权重初始化</h3>
<p>权重设置不好会导致这些权重在我们进⾏梯度下降算法时会学习得⾮常缓慢<br>
<img src="https://currydai.com/post-images/1612943333285.png" alt="" loading="lazy"><br>
<img src="https://currydai.com/post-images/1612943340982.png" alt="" loading="lazy"></p>
<h3 id="134超参数设置">1.3.4超参数设置</h3>
<ul>
<li>宽泛策略：从简单模型，简单训练样本入手</li>
<li>学习速率的选择：学习速率主要的⽬的是控制梯度下降的步⻓，监控训练代价是最好的检测步⻓过⼤的⽅法</li>
<li>使⽤提前停⽌来确定训练的迭代期数量</li>
<li>正则化参数设置</li>
<li>小批量大小选择</li>
<li>自动技术：网格搜索</li>
</ul>
<h2 id="14-神经网络可以拟合任何函数">1.4 神经网络可以拟合任何函数</h2>
<p>结果表明神经⽹络拥有⼀种普遍性。不论我们想要计算什么样的函数，我们都确信存在⼀个神经⽹络可以计算它。</p>
<h2 id="2-迈向深度学习">2 迈向深度学习</h2>
<h3 id="21-深度神经网络为何很难训练">2.1 深度神经网络为何很难训练</h3>
<p>直觉地，额外的隐藏层应当让⽹络能够学到更加复杂的分类函数，然后可以在分类时表现得更好吧。可以肯定的是，事情并没有变差，⾄少新的层次增加上，在最坏的情形下也就是没有影响5。事情并不是这样⼦的。<br>
⾄少在某些深度神经⽹络中，在我们在隐藏层 BP的时候梯度倾向于变⼩。这意味着在前⾯的隐藏层中的神经元学习速度要慢于后⾯的隐藏层。这⼉我们只在⼀个⽹络中发现了这个现象，其实在多数的神经⽹络中存在着更加根本的导致这个现象出现的原因。这个现象也被称作是消失的梯度问题。<br>
在深度神经⽹络中的梯度是不稳定的，在前⾯的层中或会消失，或会激增。这种不稳定性才是深度神经⽹络中基于梯度学习的根本问题。这就是我们需要理解的东西，如果可能的话，采取合理的步骤措施解决问题。<br>
<img src="https://currydai.com/post-images/1612944348671.png" alt="" loading="lazy"><br>
<img src="https://currydai.com/post-images/1612944424845.png" alt="" loading="lazy"><br>
两个表⽰式有很多相同的项。但是 ∂C/∂b1还多包含了两个项。由于这些项都是 &lt; 1/4 的。所以 ∂C/∂b1会是 ∂C/∂b3的 1/16 或者更⼩。这其实就是消失的梯度出现的本质原因了。</p>
<h3 id="22-深度学习">2.2 深度学习</h3>
<p><img src="https://currydai.com/post-images/1612945572024.png" alt="" loading="lazy"><br>
这个⽹络从 28 × 28 个输⼊神经元开始，这些神经元⽤于对 MNIST 图像的像素强度进⾏编码。接着的是⼀个卷积层，使⽤⼀个 5×5 局部感受野和 3 个特征映射。其结果是⼀个 3×24×24隐藏特征神经元层。下⼀步是⼀个最⼤值混合层，应⽤于 2 × 2 区域，遍及 3 个特征映射。结果是⼀个 3 × 12 × 12 隐藏特征神经元层。⽹络中最后连接的层是⼀个全连接层。更确切地说，这⼀层将最⼤值混合层的每⼀个神经元连接到每⼀个输出神经元。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[【机器学习】[2]专题：如何使用sklearn做特征工程？]]></title>
        <id>https://currydai.com/post/ji-qi-xue-xi-2zhuan-ti-jie-shao-ru-he-shi-yong-sklearn-zuo-te-zheng-gong-cheng/</id>
        <link href="https://currydai.com/post/ji-qi-xue-xi-2zhuan-ti-jie-shao-ru-he-shi-yong-sklearn-zuo-te-zheng-gong-cheng/">
        </link>
        <updated>2021-01-31T08:28:34.000Z</updated>
        <content type="html"><![CDATA[<p>参考文献：<br>
https://www.cnblogs.com/jasonfreak/p/5448385.html<br>
https://www.cnblogs.com/jasonfreak/p/5448462.html</p>
<h2 id="1什么是特征工程">1.什么是特征工程？</h2>
<p>数据和特征决定了机器学习的上限，而模型和算法只是逼近这个上限而已。特征工程本质是一项工程活动，目的是最大限度地从原始数据中提取特征以供算法和模型使用。特征处理是特征工程的核心部分，sklearn提供了较为完整的特征处理方法，包括数据预处理，特征选择，降维等<br>
<img src="https://currydai.com/post-images/1612081927588.jpg" alt="" loading="lazy"></p>
<h2 id="2特征预处理">2特征预处理</h2>
<ul>
<li><strong>不属于同一量纲</strong>：即特征的规格不一样，不能够放在一起比较。无量纲化可以解决这一问题。<br>
&lt;无量纲化&gt;使不同规格的数据转换到同一规格。常见的无量纲化方法有<strong>标准化</strong>和<strong>区间缩放法</strong>。标准化的前提是特征值服从正态分布，标准化后，其转换成标准正态分布。区间缩放法利用了边界值信息，将特征的取值区间缩放到某个特点的范围，例如[0, 1]等。<br>
&lt;标准化&gt;<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>x</mi><mo>=</mo><mfrac><mrow><mi>x</mi><mo>−</mo><mi>m</mi><mi>e</mi><mi>a</mi><mi>n</mi></mrow><mi>S</mi></mfrac></mrow><annotation encoding="application/x-tex">x=\frac {x-mean}{S}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault">x</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.1473309999999999em;vertical-align:-0.345em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.802331em;"><span style="top:-2.6550000000000002em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.05764em;">S</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">x</span><span class="mbin mtight">−</span><span class="mord mathdefault mtight">m</span><span class="mord mathdefault mtight">e</span><span class="mord mathdefault mtight">a</span><span class="mord mathdefault mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span>  -&gt; MinMaxScaler().fit_transform(data)<br>
&lt;区间缩放法&gt;<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mfrac><mrow><mi>x</mi><mo>−</mo><mi>m</mi><mi>i</mi><mi>n</mi></mrow><mrow><mi>m</mi><mi>a</mi><mi>x</mi><mo>−</mo><mi>m</mi><mi>i</mi><mi>n</mi></mrow></mfrac></mrow><annotation encoding="application/x-tex">\frac {x-min}{max-min}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.258995em;vertical-align:-0.403331em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.855664em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">m</span><span class="mord mathdefault mtight">a</span><span class="mord mathdefault mtight">x</span><span class="mbin mtight">−</span><span class="mord mathdefault mtight">m</span><span class="mord mathdefault mtight">i</span><span class="mord mathdefault mtight">n</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">x</span><span class="mbin mtight">−</span><span class="mord mathdefault mtight">m</span><span class="mord mathdefault mtight">i</span><span class="mord mathdefault mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.403331em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span> -&gt;MinMaxScaler().fit_transform(data)<br>
&lt;归一化&gt;<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mfrac><mi>x</mi><msqrt><mrow><msubsup><mo>∑</mo><mi>j</mi><mi>m</mi></msubsup><mrow><mi>x</mi><mo>[</mo><mi>j</mi><msup><mo>]</mo><mn>2</mn></msup></mrow></mrow></msqrt></mfrac></mrow><annotation encoding="application/x-tex">\frac {x} {\sqrt {\sum _j^m{x[j]^2}}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.524992em;vertical-align:-0.8295999999999999em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.695392em;"><span style="top:-2.537776em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord sqrt mtight"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9317485714285716em;"><span class="svg-align" style="top:-3.428571428571429em;"><span class="pstrut" style="height:3.428571428571429em;"></span><span class="mord mtight" style="padding-left:1.19em;"><span class="mop mtight"><span class="mop op-symbol small-op mtight" style="position:relative;top:-0.0000050000000000050004em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.7046857142857144em;"><span style="top:-2.1785614285714283em;margin-left:0em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span></span></span><span style="top:-2.8971428571428572em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathdefault mtight">m</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.46032428571428574em;"><span></span></span></span></span></span></span><span class="mspace mtight" style="margin-right:0.19516666666666668em;"></span><span class="mord mtight"><span class="mord mathdefault mtight">x</span><span class="mopen mtight">[</span><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span><span class="mclose mtight"><span class="mclose mtight">]</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7463142857142857em;"><span style="top:-2.786em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span><span style="top:-2.903748571428572em;"><span class="pstrut" style="height:3.428571428571429em;"></span><span class="hide-tail mtight" style="min-width:0.853em;height:1.5428571428571431em;"><svg width='400em' height='1.5428571428571431em' viewBox='0 0 400000 1080' preserveAspectRatio='xMinYMin slice'><path d='M95,702c-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,
-10,-9.5,-14c0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54c44.2,-33.3,65.8,
-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10s173,378,173,378c0.7,0,
35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429c69,-144,104.5,-217.7,106.5,
-221c5.3,-9.3,12,-14,20,-14H400000v40H845.2724s-225.272,467,-225.272,467
s-235,486,-235,486c-2.7,4.7,-9,7,-19,7c-6,0,-10,-1,-12,-3s-194,-422,-194,-422
s-65,47,-65,47z M834 80H400000v40H845z'/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.524822857142857em;"><span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">x</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.8295999999999999em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span> -&gt;Normalizer().fit_transform(data)<br>
此外归一化是对不同特征行之间就行的操作,标准化是对同一个特征列之间操作</li>
<li><strong>信息冗余</strong>：对于某些定量特征，其包含的有效信息为区间划分，例如学习成绩，假若只关心“及格”或不“及格”，那么需要将定量的考分，转换成“1”和“0”表示及格和未及格。二值化可以解决这一问题。<br>
&lt;定量特征二值化&gt;设定一个阈值，大于阈值的赋值为1，小于等于阈值的赋值为0<br>
Binarizer(threshold=3).fit_transform(data)</li>
<li><strong>定性特征不能直接使用</strong>：某些机器学习算法和模型只能接受定量特征的输入，那么需要将定性特征转换为定量特征。最简单的方式是为每一种定性值指定一个定量值，但是这种方式过于灵活，增加了调参的工作。<br>
通常使用&lt;哑编码&gt;的方式将定性特征转换为定量特征：假设有N种定性值，则将这一个特征扩展为N种特征，当原始特征值为第i种定性值时，第i个扩展特征赋值为1，其他扩展特征赋值为0。哑编码的方式相比直接指定的方式，不用增加调参的工作，对于线性模型来说，使用哑编码后的特征可达到非线性的效果。<br>
OneHotEncoder().fit_transform(data)</li>
<li><strong>存在缺失值</strong>：缺失值需要补充。<br>
Imputer().fit_transform(vstack((array([nan, nan, nan, nan]), data)))<br>
#缺失值计算，返回值为计算缺失值后的数据<br>
#参数missing_value为缺失值的表示形式，默认为NaN<br>
#参数strategy为缺失值填充方式，默认为mean（均值）</li>
<li><strong>信息利用率低</strong>：不同的机器学习算法和模型对数据中信息的利用是不同的，之前提到在线性模型中，使用对定性特征哑编码可以达到非线性的效果。类似地，对定量变量多项式化，或者进行其他的转换，都能达到非线性的效果。<br>
FunctionTransformer(log1p).fit_transform(.data)</li>
<li><strong>总结</strong><br>
<img src="https://currydai.com/post-images/1612092070333.png" alt="" loading="lazy"></li>
</ul>
<h2 id="3特征选择">3.特征选择</h2>
<p>当数据预处理完成后，我们需要选择有意义的特征输入机器学习的算法和模型进行训练。<br>
通常来说，从两个方面考虑来选择特征：</p>
<ol>
<li>特征是否发散：如果一个特征不发散，例如方差接近于0，也就是说样本在这个特征上基本上没有差异，这个特征对于样本的区分并没有什么用。</li>
<li><strong>特征与目标的相关性</strong>：这点比较显见，与目标相关性高的特征，应当优选选择。除方差法外，本文介绍的其他方法均从相关性考虑。</li>
</ol>
<p>根据<strong>特征选择的形式</strong>又可以将特征选择方法分为3种：</p>
<ol>
<li>
<p>Filter：过滤法，按照发散性或者相关性对各个特征进行评分，设定阈值或者待选择阈值的个数，选择特征。过滤式方法先对数据集进行特征选择，然后再训练模型，特征选择过程与后续模型训练无关</p>
<ul>
<li>方差选择法：使用方差选择法，先要计算各个特征的方差，然后根据阈值，选择方差大于阈值的特征。</li>
<li>相关系数法：使用相关系数法，先要计算各个特征对目标值的相关系数以及相关系数的P值(Pearson相关系数)。</li>
<li>卡方检测法：卡方检验就是检验两个变量之间有没有关系。卡方比线性相关系数作用会广一些，因为它没有线性的前提假设。但是卡方检验时需要查卡方临界表，但是比较相关性大小就可以不用了。https://www.zhihu.com/question/63191726</li>
<li>互信息法：互信息是两个随机变量的互信息（Mutual Information，简称MI）或转移信息（transinformation），是变量间相互依赖性的量度。通俗的来讲：互信息是一个随机变量包含另外一个随机变量的信息量，或者说如果已知一个变量，另外一个变量减少的信息量。</li>
</ul>
</li>
<li>
<p>Wrapper：包装法，根据目标函数（通常是预测效果评分），每次选择若干特征，或者排除若干特征。与过滤式特征选择不考虑后续学习器不同，包裹式特征选择直接把最终将要使用的模型的性能作为特征子集的评价标准，也就是说，包裹式特征选择的目的就是为给定的模型选择最有利于其性能的特征子集，从最终模型的性能来看，包裹式特征选择比过滤式特征选择更好，但需要多次训练模型，因此计算开销较大。</p>
<ul>
<li>递归特则消除法：递归消除特征法使用一个基模型来进行多轮训练，每轮训练后，消除若干权值系数的特征，再基于新的特征集进行下一轮训练。LVM（Las Vegas Wrapper）是一个典型的包裹式特征选择方法。它在拉斯维加斯方法框架下使用随机策略来进行子集搜索，并以最终分类器的误差为特征子集评价标准。LVW的计算开销很大，需要设置停止条件控制参数。</li>
</ul>
</li>
<li>
<p>Embedded：嵌入法，先使用某些机器学习的算法和模型进行训练，得到各个特征的权值系数，根据系数从大到小选择特征。类似于Filter方法，但是是通过训练来确定特征的优劣。嵌入式特征选择是将特征选择过程与模型训练过程融为一体，两者在同一个优化过程中完成，即在模型训练的过程中自动进行特征选择，嵌入式选择的实例是 LASSO 和 Ridge Regression</p>
<ul>
<li>基于惩罚项的特征选择法：以最简单的线性回归模型为例，其以平方误差为损失函数，则优化目标为：在样本数较少，样本特征很多的时候，容易陷入过拟合，因此可引入正则化来防止过拟合，<br>
若使用L2范数正则化，则此时优化目标的公式即为岭回归（ridge regression），若是L1范数正则化，则是LASSO回归（Least Absolute Shrinkage and Selection Operator）。L1范数和L2范数正则化都有助于降低过拟合风险，但前者还会带来一个额外的好处，它比后者更易于获得“稀疏”（sparse）解，即它求得的w会有更少的非零分类。换言之，采用L1范数比L2范数更易于得到稀疏解。注意到w取得稀疏解意味着初始的d个特征中仅有对应着w的非零分量的特征才会出现在最终模型中，于是，求解L1范数正则化的结果是得到了仅采用一部分初始特征的模型；所以，基于L1正则化的学习方法就是一种嵌入式特征选择方法，其特征选择过程与学习器训练过程融为一体，同时完成。此外，L1正则化问题的求解可使用近端梯度下降（Proximal Gradient Descent，PGD），即在每一步对f(x)进行梯度下降迭代的同时考虑L1范数最小化。通过PGD能使LASSO和其它基于L1范数最小化的方法得以快速求</li>
<li>基于树模型的特征选择法：树模型中GBDT也可用来作为基模型进行特征选择，由于决策树算法在构建树的同时也可以看作进行了特征选择，因此嵌入式方法可以追溯到 ID3 算法。</li>
</ul>
</li>
<li>
<p>总结<br>
<img src="https://currydai.com/post-images/1612093652618.png" alt="" loading="lazy"></p>
</li>
</ol>
<h2 id="4降维">4.降维</h2>
<p>当特征选择完成后，可以直接训练模型了，但是可能由于特征矩阵过大，导致计算量大，训练时间长的问题，因此降低特征矩阵维度也是必不可少的。常见的降维方法除了以上提到的基于L1惩罚项的模型以外，另外还有主成分分析法（PCA）和线性判别分析（LDA），线性判别分析本身也是一个分类模型。PCA和LDA有很多的相似点，其本质是要将原始的样本映射到维度更低的样本空间中，但是PCA和LDA的映射目标不一样：PCA是为了让映射后的样本具有最大的发散性；而LDA是为了让映射后的样本有最好的分类性能。所以说PCA是一种无监督的降维方法，而LDA是一种有监督的降维方法。</p>
<ol>
<li>PCA</li>
<li>LDA</li>
</ol>
<h2 id="5如何操作">5.如何操作</h2>
<ol>
<li>数据挖掘的步骤</li>
</ol>
<p>数据挖掘通常包括数据采集，数据分析，特征工程，训练模型，模型评估等步骤。使用sklearn工具可以方便地进行特征工程和模型训练工作，特征处理类都有三个方法fit、transform和fit_transform，fit方法居然和模型训练方法fit同名，这正是sklearn的设计风格。我们能够更加优雅地使用sklearn进行特征工程和模型训练工作。此时，不妨从一个基本的数据挖掘场景入手：<br>
<img src="https://currydai.com/post-images/1612095039626.png" alt="" loading="lazy"><br>
我们使用sklearn进行虚线框内的工作（sklearn也可以进行文本特征提取）。通过分析sklearn源码，我们可以看到除训练，预测和评估以外，处理其他工作的类都实现了3个方法：fit、transform和fit_transform。从命名中可以看到，fit_transform方法是先调用fit然后调用transform，我们只需要关注fit方法和transform方法即可。transform方法主要用来对特征进行转换。从可利用信息的角度来说，转换分为无信息转换和有信息转换。无信息转换是指不利用任何其他信息进行转换，比如指数、对数函数转换等。有信息转换从是否利用目标值向量又可分为无监督转换和有监督转换。无监督转换指只利用特征的统计信息的转换，统计信息包括均值、标准差、边界等等，比如标准化、PCA法降维等。有监督转换指既利用了特征信息又利用了目标值信息的转换，比如通过模型选择特征、LDA法降维等。通过总结常用的转换类，我们得到下表：<br>
<img src="https://currydai.com/post-images/1612095155373.png" alt="" loading="lazy"><br>
不难看到，只有有信息的转换类的fit方法才实际有用，显然fit方法的主要工作是获取特征信息和目标值信息，在这点上，fit方法和模型训练时的fit方法就能够联系在一起了：都是通过分析特征和目标值，提取有价值的信息，对于转换类来说是某些统计量，对于模型来说可能是特征的权值系数等。另外，只有有监督的转换类的fit和transform方法才需要特征和目标值两个参数。fit方法无用不代表其没实现，而是除合法性校验以外，其并没有对特征和目标值进行任何处理，Normalizer的fit方法实现如下：</p>
<ol start="2">
<li>并行加速</li>
</ol>
<p>基于这些特征处理工作都有共同的方法，那么试想可不可以将他们组合在一起？在本文假设的场景中，我们可以看到这些工作的组合形式有两种：流水线式和并行式。基于流水线组合的工作需要依次进行，前一个工作的输出是后一个工作的输入；基于并行式的工作可以同时进行，其使用同样的输入，所有工作完成后将各自的输出合并之后输出。sklearn提供了包pipeline来完成流水线式和并行式的工作。<br>
并行处理，流水线处理，自动化调参，持久化是使用sklearn优雅地进行数据挖掘的核心。并行处理和流水线处理将多个特征处理工作，甚至包括模型训练工作组合成一个工作（从代码的角度来说，即将多个对象组合成了一个对象）。在组合的前提下，自动化调参技术帮我们省去了人工调参的反锁。训练好的模型是贮存在内存中的数据，持久化能够将这些数据保存在文件系统中，之后使用时无需再进行训练，直接从文件系统中加载即可。</p>
<ul>
<li>并行处理</li>
<li>流水线处理</li>
<li>自动化调参</li>
<li>持久化</li>
</ul>
<figure data-type="image" tabindex="1"><img src="https://currydai.com/post-images/1612095383070.png" alt="" loading="lazy"></figure>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[【机器学习】[1]专题：知识框架总览]]></title>
        <id>https://currydai.com/post/ji-qi-xue-xi-zhi-shi-dian-bu-chong/</id>
        <link href="https://currydai.com/post/ji-qi-xue-xi-zhi-shi-dian-bu-chong/">
        </link>
        <updated>2021-01-30T14:11:28.000Z</updated>
        <content type="html"><![CDATA[<h3 id="1-机器学习包含哪些内容">1. 机器学习包含哪些内容？</h3>
<ul>
<li><strong>监督学习：</strong>
<ul>
<li>线性回归</li>
<li>逻辑回归</li>
<li>随机森林</li>
<li>梯度下降决策树</li>
<li>SVM</li>
<li>神经网络</li>
<li>决策树</li>
<li>朴素贝叶斯</li>
<li>KNN</li>
</ul>
</li>
<li><strong>无监督学习：</strong>
<ul>
<li>K-Means聚类</li>
<li>t-SNE</li>
<li>PCA</li>
<li>关联规则</li>
</ul>
</li>
<li><strong>半监督学习：</strong>
<ul>
<li>图论推理算法</li>
<li>及拉普拉斯支持向量机</li>
</ul>
</li>
<li><strong>强化学习：</strong>
<ul>
<li>Q-learning</li>
<li>瞬时差分(TD)</li>
<li>蒙特卡洛树搜索</li>
<li>A3C</li>
</ul>
</li>
</ul>
<h3 id="2-sklearn到底有什么"><strong>2. sklearn到底有什么？</strong></h3>
<h4 id="21-监督学习"><strong>2.1 监督学习</strong></h4>
<ol>
<li>广义线性模型
<ul>
<li>普通最小二乘</li>
<li>岭回归(L2正则化)</li>
<li>Lasso回归(L1正则化)</li>
<li>多任务Lasso</li>
<li>弹性网络</li>
<li>多任务弹性网络</li>
<li>最小角回归</li>
<li>LARS Lasso</li>
<li>正交匹配追踪法(OMP)</li>
<li>贝叶斯回归</li>
<li>逻辑回归(分类)</li>
<li>随机梯度下降SGD</li>
<li>感知器</li>
<li>被动攻击算法</li>
<li>稳健回归</li>
<li>Huber 回归</li>
<li>多项式回归</li>
</ul>
</li>
<li>线性和二次判别分析</li>
<li>内核岭回归</li>
<li>支持向量机</li>
<li>随机维度下降</li>
<li>最邻近</li>
<li>高斯过程</li>
<li>交叉分解</li>
<li>朴素贝叶斯</li>
<li>决策树</li>
<li>集成方法</li>
<li>多类与多标签算法特征选择</li>
<li>半监督学习</li>
<li>等式回归</li>
<li>概率校准</li>
<li>神经网络模型(有监督)</li>
</ol>
<h4 id="22-无监督学习"><strong>2.2 无监督学习</strong></h4>
<ol start="17">
<li>高斯混合模型</li>
<li>流形学习</li>
<li>聚类</li>
<li>双聚类</li>
<li>分解成分中的信号</li>
<li>协方差估计</li>
<li>新奇和异常值估计</li>
<li>密度估计</li>
<li>神经网络模型(无监督)</li>
</ol>
<h4 id="23-模型选择和评估"><strong>2.3 模型选择和评估</strong></h4>
<ol>
<li>交叉验证</li>
<li>调整估计器的超参数</li>
<li>模型评估：量化预测的质量</li>
<li>模型持久化</li>
<li>验证曲线</li>
</ol>
<h4 id="24-数据预处理与计算手段"><strong>2.4 数据预处理与计算手段</strong></h4>
<ol>
<li>检验：部份依赖图</li>
<li>数据集转换
<ul>
<li>特征联合：Pipeline和Features</li>
<li>特征提取</li>
<li>预处理数据</li>
<li>缺失值插补</li>
<li>无监督降维</li>
<li>随机投影</li>
<li>内核近似</li>
<li>成对的矩阵类别和核函数</li>
<li>预测目标的抓换</li>
</ul>
</li>
<li>数据集加载工具
<ul>
<li>通用数据集API</li>
<li>玩具数据集</li>
<li>真实世界中的数据集</li>
<li>样本生成器</li>
<li>加载其他数集</li>
</ul>
</li>
<li>优化计算
<ul>
<li>大规模计算的策略</li>
<li>计算性能</li>
<li>并行性、资源管理和配置</li>
</ul>
</li>
</ol>
<h3 id="3-tips"><strong>3. Tips</strong></h3>
<h4 id="1l1正则化与l2正则化区别"><strong>1.L1正则化与L2正则化区别</strong></h4>
<p>(https://zhuanlan.zhihu.com/p/29360425)(https://zhuanlan.zhihu.com/p/85630046)<br>
正则化（Regularization）是机器学习中一种常用的技术，其主要目的是控制模型复杂度，减小过拟合。最基本的正则化方法是在原目标（代价）函数 中添加惩罚项，对复杂度高的模型进行惩罚。<br>
<img src="https://currydai.com/post-images/1612079169793.png" alt="" loading="lazy"><br>
- L1正则化：通过稀疏化参数来降低复杂度,可以用来做特征选择<br>
损失函数：<br>
<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>L</mi><mo>(</mo><mi>w</mi><mo>)</mo><mo>=</mo><msub><mi>E</mi><mi>D</mi></msub><mo>(</mo><mi>w</mi><mo>)</mo><mo>+</mo><mfrac><mi>λ</mi><mi>n</mi></mfrac><msubsup><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></msubsup><mrow><mi mathvariant="normal">∣</mi><msub><mi>w</mi><mi>i</mi></msub><mi mathvariant="normal">∣</mi></mrow></mrow><annotation encoding="application/x-tex">L(w)=E_D(w)+\frac \lambda {n} \sum_{i=1}^n{|w_i|}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault">L</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.02691em;">w</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05764em;">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.02778em;">D</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.02691em;">w</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.2251079999999999em;vertical-align:-0.345em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8801079999999999em;"><span style="top:-2.6550000000000002em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">n</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">λ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:-0.0000050000000000050004em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.804292em;"><span style="top:-2.40029em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.2029em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.29971000000000003em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord">∣</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord">∣</span></span></span></span></span><br>
作用：更容易在棱角处取得最优值导致某些w取零<br>
- L2正则化：通过减少参数值的大小降低复杂度<br>
损失函数：<br>
<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>L</mi><mo>(</mo><mi>w</mi><mo>)</mo><mo>=</mo><msub><mi>E</mi><mi>D</mi></msub><mo>(</mo><mi>w</mi><mo>)</mo><mo>+</mo><mfrac><mi>λ</mi><mrow><mn>2</mn><mi>n</mi></mrow></mfrac><msubsup><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></msubsup><msubsup><mi>w</mi><mi>i</mi><mn>2</mn></msubsup></mrow><annotation encoding="application/x-tex">L(w)=E_D(w)+\frac \lambda {2n} \sum_{i=1}^n{w_i^2}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault">L</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.02691em;">w</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05764em;">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.02778em;">D</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.02691em;">w</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.2251079999999999em;vertical-align:-0.345em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8801079999999999em;"><span style="top:-2.6550000000000002em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span><span class="mord mathdefault mtight">n</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">λ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:-0.0000050000000000050004em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.804292em;"><span style="top:-2.40029em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.2029em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.29971000000000003em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord"><span class="mord mathdefault" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-2.441336em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.258664em;"><span></span></span></span></span></span></span></span></span></span></span></p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[【ML实践】[Kaggle1]House Prices - Advanced Regression Techniques]]></title>
        <id>https://currydai.com/post/kaggle-house-prices-advanced-regression-techniques/</id>
        <link href="https://currydai.com/post/kaggle-house-prices-advanced-regression-techniques/">
        </link>
        <updated>2021-01-30T08:22:19.000Z</updated>
        <content type="html"><![CDATA[<h2 id="1目的">1.目的</h2>
<pre><code>预测房价，需要从众多可能的影响因子中挑选出最能预测房价的因子来建立模型，用于预测房价。
</code></pre>
<h2 id="2思路">2.思路</h2>
<pre><code>数据分布特征-&gt;挑选特征-&gt;交叉验证-&gt;选择模型-&gt;实现预测
</code></pre>
<h2 id="3处理">3.处理</h2>
<h3 id="31特征可视化分析">3.1特征可视化分析</h3>
<pre><code>SalePrice - the property's sale price in dollars. This is the target 
1.MSSubClass: The building class 建筑类别
2.MSZoning: The general zoning classification 常规分区分类
3.LotFrontage: Linear feet of street connected to property 连接物业距离
4.LotArea: Lot size in square feet 平方尺大小
5.Street: Type of road access 道路通行类型
6.Alley: Type of alley access 胡同通道类型
7.LotShape: General shape of property 形状
8.LandContour: Flatness of the property 房屋平整度
9.Utilities: Type of utilities available 实用类性
10.LotConfig: Lot configuration 批次配置
11.LandSlope: Slope of property 物业的坡度
12.Neighborhood: Physical locations within Ames city limits 市区的地理位置
13.Condition1: Proximity to main road or railroad 接近主要公路或铁路
14.Condition2: Proximity to main road or railroad (if a second is present)
15.BldgType: Type of dwelling 住宅类型
16.HouseStyle: Style of dwelling 住宅风格
17.OverallQual: Overall material and finish quality 整体材料和表面质量
18.OverallCond: Overall condition rating 总体状况评分
19.YearBuilt: Original construction date 原始施工日期
20.YearRemodAdd: Remodel date 改型日期
21.RoofStyle: Type of roof 屋顶类型
22.RoofMatl: Roof material 屋顶材料
23.Exterior1st: Exterior covering on house 房屋外墙
24.Exterior2nd: Exterior covering on house (if more than one material)
25.MasVnrType: Masonry veneer type 石工饰面类型
26.MasVnrArea: Masonry veneer area in square feet 砌面贴面面积
27.ExterQual: Exterior material quality 外部材料质量
28.ExterCond: Present condition of the material on the exterior 外部材料状态
29.Foundation: Type of foundation 基础类型
30.BsmtQual: Height of the basement 地下室的高度
31.BsmtCond: General condition of the basement 地下室的一般状况
32.BsmtExposure: Walkout or garden level basement walls 地下室墙
33.BsmtFinType1: Quality of basement finished area 地下室成品区域的质量
34.BsmtFinSF1: Type 1 finished square feet 1型成品平方英尺
35.BsmtFinType2: Quality of second finished area (if present)
36.BsmtFinSF2: Type 2 finished square feet 2型成品平方英尺
37.BsmtUnfSF: Unfinished square feet of basement area 地下室未完成的平方英尺
38.TotalBsmtSF: Total square feet of basement area 地下室总平方英尺
39.Heating: Type of heating 加热方式
40.HeatingQC: Heating quality and condition 加热质量和条件
41.CentralAir: Central air conditioning 中央空调
42.Electrical: Electrical system  电气系统
43.1stFlrSF: First Floor square feet 一楼平方英尺
44.2ndFlrSF: Second floor square feet 二楼平方英尺
45.LowQualFinSF: Low quality finished square feet (all floors)低质量成品平方
46.GrLivArea: Above grade (ground) living area square feet地面以上的居住面积
47.BsmtFullBath: Basement full bathrooms 地下室完整的浴室
48.BsmtHalfBath: Basement half bathrooms 地下室半浴室
49.FullBath: Full bathrooms above grade 满级浴室
50.HalfBath: Half baths above grade 半浴
51.Bedroom: Number of bedrooms above basement level 卧室数量
52.Kitchen: Number of kitchens 厨房数量
53.KitchenQual: Kitchen quality 厨房质量
54.TotRmsAbvGrd: Total rooms above grade (does not include bathrooms) 客房
55.Functional: Home functionality rating 家庭功能等级
56.Fireplaces: Number of fireplaces 壁炉数量
57.FireplaceQu: Fireplace quality 壁炉质量
58.GarageType: Garage location 车库位置
59.GarageYrBlt: Year garage was built 年车库已建成
60.GarageFinish: Interior finish of the garage 车库的内部装饰
61.GarageCars: Size of garage in car capacity 车库中车库的大小
62.GarageArea: Size of garage in square feet 车库的大小（平方英尺）
63.GarageQual: Garage quality 车库质量
64.GarageCond: Garage condition  车库条件
65.PavedDrive: Paved driveway  铺砌的车道
66.WoodDeckSF: Wood deck area in square feet  木制甲板面积
67.OpenPorchSF: Open porch area in square feet 开放式阳台面积
68.EnclosedPorch: Enclosed porch area in square feet 封闭式门廊面积
69.3SsnPorch: Three season porch area in square feet 平方英尺的三季门廊面积
70.ScreenPorch: Screen porch area in square feet  屏幕门廊面积
71.PoolArea: Pool area in square feet 游泳池面积
72.PoolQC: Pool quality 泳池质量
73.Fence: Fence quality 围栏质量
74.MiscFeature: Miscellaneous feature not covered in other categories 杂项
75.MiscVal: Value of miscellaneous feature 杂项功能的值
76.MoSold: Month Sold 已售一个月
77.YrSold: Year Sold 年售
78.SaleType: Type of sale  销售类型
79.SaleCondition: Condition of sale 销售条件
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[【ML实践】[Kaggle2]Indoor Location & Navigation]]></title>
        <id>https://currydai.com/post/kaggle-2-1indoor-location-and-navigation/</id>
        <link href="https://currydai.com/post/kaggle-2-1indoor-location-and-navigation/">
        </link>
        <updated>2021-01-30T02:36:30.000Z</updated>
        <content type="html"><![CDATA[<h3 id="1description">1.Description</h3>
<p>Your smartphone goes everywhere with you—whether driving to the grocery store(杂货店)or shopping for holiday gifts. With your permission, apps can use your location to provide contextual information. You might get driving directions, find a store, or receive alerts for nearby promotions. These handy features are enabled by GPS, which requires outdoor exposure for the best accuracy. Yet, there are many times when you're inside large structures, such as a shopping mall or event center. Accurate indoor positioning, based on public sensors and user permission, allows for a great location-based experience even when you aren't outside.</p>
<p>Current positioning solutions have poor accuracy, particularly in multi-level buildings, or generalize poorly to small datasets. Additionally, GPS was built for a time before smartphones. Today's use cases often require more granularity(粒度) than is typically available indoors.</p>
<p>In this competition, your task is to predict the indoor position of smartphones based on real-time sensor data, provided by indoor positioning technology company XYZ10 in partnership with Microsoft Research. You'll locate devices using “active” localization data, which is made available with the cooperation of the user. Unlike passive(被动的) localization methods (e.g. radar, camera), the data provided for this competition requires explicit user permission. You'll work with a dataset of nearly 30,000 traces from over 200 buildings.</p>
<p>If successful, you'll contribute to research with broad-reaching possibilities, including industries like manufacturing, retail, and autonomous devices. With more accurate positioning, existing location-based apps could even be improved. Perhaps you’ll even see the benefits yourself the next time you hit the mall.</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[【English】Some thoughts on learning English]]></title>
        <id>https://currydai.com/post/english-some-thoughts-on-learning-english/</id>
        <link href="https://currydai.com/post/english-some-thoughts-on-learning-english/">
        </link>
        <updated>2021-01-28T13:58:46.000Z</updated>
        <content type="html"><![CDATA[<p>I need to prepare the antrance test and the EILS in two months,but i always find the excuse that i have no spare time to study English.When Filipe who is my best friend listened this,He uncovered this lie .So i learned something from him.<br>
We always find some excuses to advoid doing these things what we do not want to do .Actually we are mainly lack of self-control.As long as you want to learn, you can learn anywhere or anytime.<br>
<img src="https://currydai.com/post-images/1611843696072.png" alt="" loading="lazy"></p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[【编程】C++学习与进阶]]></title>
        <id>https://currydai.com/post/c-ji-chu-zhi-shi-hui-gu/</id>
        <link href="https://currydai.com/post/c-ji-chu-zhi-shi-hui-gu/">
        </link>
        <updated>2021-01-27T04:03:19.000Z</updated>
        <content type="html"><![CDATA[<h2 id="1主要内容包括">1.主要内容包括：</h2>
<pre><code>- C++远征之起航篇
- C++远征之封装篇
- C++远征之继承篇
- C++远征之多态篇
- C++远征之模板篇
- C++远征之离港篇
</code></pre>
<h2 id="2c远征之起航篇">2.C++远征之起航篇</h2>
<pre><code>Pass
</code></pre>
<h2 id="3c远征之离港篇">3.C++远征之离港篇</h2>
<pre><code>* 引用：就是变量的别名，int &amp;y=x
* const与指针类关系,*y是内用（数据），y是指针（指向关系）
* const与引用关系，&amp;y两层含义，在左边是定义引用关系，在右边是取地址操作
</code></pre>
<h2 id="4c远征之封装篇">4.C++远征之封装篇</h2>
<ul>
<li>类外定义</li>
<li>内存五区：栈 堆 全局区 常量区 代码区</li>
<li>对象放在栈区，方法放在代码区供不同对象调用</li>
<li>对象初始化：构造函数，初始化列表</li>
<li>构造函数：有且自动执行一次，与类重名，无返回值，多个重载，无构造函数时编译器自动生成</li>
<li>拷贝构造函数：浅拷贝 深拷贝</li>
<li>对象指针：把对象生命成指针，Coordinate *p=new Coordinate;p-&gt;m_iX=1;p-&gt;m_iY=2;</li>
<li>对象成员：作为一个对象来说，他成为另外一个类的数据成员</li>
<li>对象成员指针：对象的指针作为另外一个类的数据成员。在类中使用了对象成员指针后，在析构函数中要删除指针！</li>
<li>this指针：this指向对象的指针</li>
<li>常对象成员：常对象只能调用常成员函数，不能调用普通函数；普通对象能够调用常成员函数，也能调用普通成员函数。</li>
<li>常指针vs常引用</li>
</ul>
<h2 id="5c远征之继承篇">5.C++远征之继承篇</h2>
<ul>
<li>基类/派生类 父类/子类</li>
<li>继承方式：公有继承/保护继承/私有继承<br>
<img src="https://currydai.com/post-images/1613890403790.png" alt="" loading="lazy"><br>
<img src="https://currydai.com/post-images/1613910614401.png" alt="" loading="lazy"><br>
<img src="https://currydai.com/post-images/1613910646580.png" alt="" loading="lazy"><br>
不同继承方式的影响主要体现在：<br>
1、<strong>派生类成员</strong>对基类成员的访问控制。<br>
2、<strong>派生类对象</strong>对基类成员的访问控制。<br>
三种继承方式：<br>
1、公有继承（public）<br>
① 基类的public和protected成员的访问属性在派生类中保持不变，但基类的private成员不可访问。<br>
② 派生类中的成员函数可以直接访问基类中的public和protected成员，但不能访问基类的private成员。<br>
③ 通过派生类的对象只能访问基类的public成员。<br>
2、私有继承（private）<br>
① 基类的public和protected成员都以private身份出现在派生类中，但基类的private成员不可访问。<br>
② 派生类中的成员函数可以直接访问基类中的public和protected成员，但不能访问基类的private成员<br>
③ 通过派生类的对象不能访问基类中的任何成员。<br>
3、保护继承（protected）<br>
① 基类的public和protected成员都以protected身份出现在派生类中，但基类的private成员不可访问。<br>
② 派生类中的成员函数可以直接访问基类中的public和protected成员，但不能访问基类的private成员。<br>
③ 通过派生类的对象不能访问基类中的任何成员。<br>
protected成员的特点与作用：<br>
对建立其所在类对象的模块来说（水平访问时），它与private成员性质相同。对于其派上类来说（垂直访问时），它与public成员的性质相同。既实现了数据隐藏，又方便继承，实现了代码重用。</li>
<li>隐藏：父子关系 成员同名</li>
<li>is a</li>
<li>多重继承</li>
<li>多继承</li>
<li>虚继承：只要是父类虚继承，子类都是默认虚继承，也就是说子类的子类也是虚继承，子类的子类的子类也是虚继承</li>
</ul>
<h2 id="6c远征之多态篇">6.C++远征之多态篇</h2>
<ul>
<li>多态：相同对象收到不同消息或者不同对象收到相同消息时产生不同的动作</li>
<li>静态多态（早绑定）：单个类</li>
<li>动态多态（晚绑定）：以封装和继承为基础（多个类）</li>
<li>虚函数：父类想要实现多态的成员函数前加virtual，子类同时也要加（不加系统自动加）</li>
<li>虚析构函数：解决多态过程中内存泄露问题</li>
<li>virtual:1.不能修饰普通函数2.不同修饰静态函数3.不能修饰内联函数4.不能修饰构造函数</li>
<li>函数的覆盖和隐藏</li>
<li>虚函数表</li>
<li>纯虚函数</li>
<li>抽象类：含有纯虚函数的类，抽象类无法实例化对象</li>
<li>接口类：仅含有纯虚函数的类成为接口类，只有成员函数，成员函数都是纯虚函数。接口类更多表达一种能力和协议</li>
<li>RTTI:运行时类型识别</li>
<li>异常处理：try....catch...       throw</li>
<li>常见的异常：数组下表越界+除数为0+内存不足</li>
</ul>
<h2 id="7c远征之模板篇">7.C++远征之模板篇</h2>
<ul>
<li>模板函数 模板类 标准模板类</li>
<li></li>
</ul>
<h2 id="finalc基础知识持续补充">Final:C++基础知识(持续补充)</h2>
<p>C++全称为c with classes,由Enter Bjarne Stroustrup在使用Simula(首次使用类的语言)编写用于分布式计算机系统的模拟器时，希望有一种高效和模块化的工具，于是在C的基础上为C增加了类机制，也就是面向对象，1983年完成了C++的第一个版本。C++相比于C有以下特点：</p>
<ol>
<li>完全兼容C语法(指针等)</li>
<li>支持面向对象的编程思想</li>
<li>支持运算符重载</li>
<li>支持泛型编程与模板</li>
<li>支持异常处理</li>
<li>类型检查严格<br>
C++作为一个高级编程思想，并不只是仅仅支持一个面向对象的编程思想，还包括面向过程、模板(泛型编程)等思想，应用在不同的方面上，以提高代码的使用率以及效率。</li>
</ol>
<h3 id="1指针与引用">1.指针与引用</h3>
<p><strong>指针</strong>：对于一个类型T，T*就是指向T的指针类型。也就是一个T*类型的变量能够保存一个T对象的地址，T可以加入一些限定词，比如const、volatile等<br>
<strong>引用</strong>：引用是一个对象的别名，主要用于函数参数和返回值类型，T&amp;表示T类型的引用</p>
<ol>
<li><strong>引用不可以为空，指针可以为空</strong>-&gt;引用定义必须初始化,使用指针前必须判空操作</li>
<li><strong>引用不可以改变指向，但可以更改初始化对象的内容</strong>-&gt;引用的改变是对象，指向不变</li>
<li><strong>引用的大小是所指向的变量的大小，指针的大小之指针类型的大小(四字节)</strong></li>
<li><strong>引用比指针更安全，不存在空引用</strong>-&gt;const指针虽然不能改变指向但有可能存在空指针<br>
<strong>const</strong></li>
<li><strong>常量指针</strong>：指向常量的指针-&gt;在指针定义语句的类型前加const,表示指向的对象是常量</li>
<li><strong>常量引用</strong>：指向常量的引用-&gt;在引用定义语句的类型加const，表示指向的对象是常量</li>
<li><strong>指针常量</strong>：指针本身是常量-&gt;在指针定义语句的指针名前加const，必须初始化</li>
<li><strong>引用常量</strong>：引用天生俱来的属性，不用在加const</li>
<li><strong>常量指针常量</strong>：指向常量的指针常量-&gt;必须初始化并且不能当作左值赋值<br>
<strong>总结&lt;1&gt;</strong>：const:无非是修饰指针还是指针指向的数据，助记方法：以*号为分界线，如果是出现在右边，修饰指针为指针常量；如果在左边，修饰数据为常量指针。而引用本身就是指针常量，不可以改变指向。<br>
<strong>总结&lt;2&gt;</strong>：引用做函数参数-&gt;函数传参，可以利用引用的技术让形参修饰实参，可以简化指针修改实参<br>
引用做函数返回值-&gt;在内存中不产生被返回值的副本</li>
</ol>
<h2 id="2结构体">2.结构体</h2>
<pre><code>typedef struct{
    int x;
    iny y;
}Coord;
</code></pre>
<h2 id="3宏定义">3.宏定义</h2>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[【导语】世界那么大，很高兴遇见你]]></title>
        <id>https://currydai.com/post/Nice to meet you/</id>
        <link href="https://currydai.com/post/Nice to meet you/">
        </link>
        <updated>2021-01-22T14:56:49.000Z</updated>
        <content type="html"><![CDATA[<h3 id="2021122-开题">2021.1.22  开题</h3>
<p>大家好，我是<strong>Curry</strong><br>
一个热爱技术热爱生活的年轻人</p>
<p>初入社会却对未来充满迷茫<br>
原来每个人对幸福的定义都不相同<br>
通过聆听他们的故事<br>
发现所谓的幸福就在身边</p>
<p>于是我开始寻找<br>
寻找自己的脚印<br>
探索自己的幸福<br>
我希望有个平台能记录我的过程<br>
开心、难过、骄傲、进步<br>
于是我创办了这个博客</p>
<p>关于未来博客的创作<br>
我也不知道要写什么<br>
至少能让我成长的事情都会记录下来<br>
技术分享、旅游故事、爱情故事甚至人生感悟<br>
如果您有幸看到我的故事，我的分享<br>
或许可能给你带来帮助或者欢笑<br>
那就足够了<br>
<strong>Go,Curry!</strong></p>
<h3 id="2021210-定义">2021.2.10  定义</h3>
<p>经过一个月的思考与学习<br>
未来的分为四大模块<br>
<strong>数学基础-Math</strong><br>
<strong>编程技术-Program</strong><br>
<strong>机器学习-Machine</strong><br>
<strong>生活感悟-Life</strong></p>
<h3 id="2021217-感悟">2021.2.17 感悟</h3>
<p>找一份你喜欢的行业<br>
这个行业又能赚钱<br>
你能成为这个领域的专家<br>
那么这就是最好的选择</p>
<h3 id="2021220-感悟">2021.2.20 感悟</h3>
<p>转型是痛苦的<br>
前进是艰难的<br>
诱惑是巨大的<br>
不忘初心<br>
砥砺前行</p>
<h3 id="2021313-感悟">2021.3.13 感悟</h3>
<p>每一次前进<br>
暗示着过去的黑暗<br>
每一次抉择<br>
暗示着自我的拯救</p>
<p>路漫漫其修远兮<br>
吾将上下而求索</p>
<h3 id="2021317-感悟">2021.3.17 感悟</h3>
<p>聚焦<br>
才能深入</p>
<h3 id="2021419感悟">2021.4.19感悟</h3>
<p>温水煮青蛙<br>
不进则退</p>
<p>朝三暮四<br>
要保持专注！！！！！</p>
]]></content>
    </entry>
</feed>